{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistiques Appliquées"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python 3.5 needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factorization of matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Factorization (MF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Creating the new matrix\n",
    "def MF(A,d=15,steps=100,alpha=0.0001,beta=0.0001,threshold=0.01):\n",
    "    n,m = A.shape\n",
    "    P=np.random.rand(n,d)\n",
    "    Q=np.random.rand(d,m)\n",
    "    for step in range(steps):\n",
    "        P += alpha * (2*(A @ Q.T - P @ Q @ Q.T) - beta * P)\n",
    "        Q += alpha * (2*(P.T @ A - P.T @ P @ Q) - beta * Q)\n",
    "        PQ = P @ Q\n",
    "        euclidean = np.nansum((A-PQ)**2)\n",
    "        if euclidean < threshold:\n",
    "            break\n",
    "    print(\"The euclidean distance is {d}\".format(d=euclidean))\n",
    "    return(PQ, P, Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's apply it on a matrix of 1s and 5s, with perturbation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dimension of latent space\n",
    "d=15\n",
    "\n",
    "nbUsers = 943\n",
    "nbFilms = 1682\n",
    "\n",
    "# Create matrices\n",
    "def simulateData(d=15, sigma=0, nbRows = 943, nbCols = 1682):\n",
    "    newData = np.ones((nbRows,nbCols))\n",
    "    \n",
    "    \n",
    "    rowSplits = np.sort(np.random.choice(range(1,nbRows), d-1, replace=False))\n",
    "    rowStarts = np.concatenate([np.array([0]),rowSplits]) \n",
    "     \n",
    "    colSplits = np.sort(np.random.choice(range(1,nbCols), d-1, replace=False))\n",
    "    colStarts = np.concatenate([np.array([0]),colSplits])\n",
    "    \n",
    "    for i in range(1,d):\n",
    "        fives = np.zeros((rowStarts[i]-rowStarts[i-1],colStarts[i]-colStarts[i-1]))+5\n",
    "        newData[rowStarts[i-1]:rowStarts[i],colStarts[i-1]:colStarts[i]] = fives\n",
    "    \n",
    "    fives = np.zeros((nbRows-rowStarts[d-1],nbCols-colStarts[d-1]))+5\n",
    "    newData[rowStarts[d-1]:,colStarts[d-1]:] = fives\n",
    "    \n",
    "    \n",
    "    newData += sigma * (np.random.randn(nbRows,nbCols)-1/2)\n",
    "    return newData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The euclidean distance is 126398.80419450438\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[ 0.97180892,  0.99498776,  1.1676196 , ...,  1.12670146,\n",
       "          0.89410988,  1.12613139],\n",
       "        [ 1.08812725,  1.04660435,  1.18471553, ...,  1.07965429,\n",
       "          0.95734531,  1.11357196],\n",
       "        [ 1.05089552,  0.98252975,  1.1014586 , ...,  1.05972373,\n",
       "          0.92200987,  1.13767892],\n",
       "        ..., \n",
       "        [ 1.24245738,  1.44160698,  1.18022623, ...,  4.34233762,\n",
       "          4.4781173 ,  4.2499739 ],\n",
       "        [ 1.25508738,  1.44777677,  1.18170276, ...,  4.37136214,\n",
       "          4.46433653,  4.25700511],\n",
       "        [ 1.22178466,  1.48267549,  1.13399294, ...,  4.42132438,\n",
       "          4.4377212 ,  4.28203156]]),\n",
       " array([[  1.88034665e-01,  -1.81994604e-02,  -1.91208504e-02, ...,\n",
       "           8.03363735e-02,   3.26088633e-01,  -1.95685459e-02],\n",
       "        [  1.26785453e-01,   1.86593265e-04,  -1.85543703e-01, ...,\n",
       "           1.68447659e-01,   2.70097554e-01,  -2.41648408e-03],\n",
       "        [  9.04116705e-02,  -1.69095555e-03,  -3.33906640e-02, ...,\n",
       "           1.35055756e-01,   2.97915787e-01,  -1.00629978e-01],\n",
       "        ..., \n",
       "        [  1.02034757e+00,   6.25848301e-01,  -1.43512579e+00, ...,\n",
       "          -5.61643399e-01,  -2.16789366e-01,  -1.38371215e+00],\n",
       "        [  1.04460345e+00,   6.55031099e-01,  -1.41646790e+00, ...,\n",
       "          -5.76039237e-01,  -2.38331635e-01,  -1.43484448e+00],\n",
       "        [  1.06104948e+00,   6.92322644e-01,  -1.38940828e+00, ...,\n",
       "          -6.08193577e-01,  -1.68945864e-01,  -1.38581271e+00]]),\n",
       " array([[-0.03053086,  0.4536036 ,  0.36424352, ...,  0.82807766,\n",
       "          0.71619439,  0.47475033],\n",
       "        [ 0.37605876,  0.36257544,  0.16894298, ...,  0.61699446,\n",
       "          0.43898643,  0.65940378],\n",
       "        [ 0.0514735 ,  0.24066508,  0.0512554 , ...,  0.11938613,\n",
       "         -0.16727219,  0.10132335],\n",
       "        ..., \n",
       "        [ 0.48640152,  0.46320048,  0.74852381, ...,  0.12833544,\n",
       "          0.44216485,  0.53045093],\n",
       "        [ 0.69130205,  0.51312062,  0.80705783, ...,  0.51978617,\n",
       "          0.17589289,  0.50280031],\n",
       "        [ 0.29637536,  0.47447585,  0.22739984, ..., -0.02511682,\n",
       "          0.16069214, -0.14981447]]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = simulateData(15,0.05,943,1682)\n",
    "MF(A,15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-Negative Matrix Factorization (NMF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refers to the article : http://papers.nips.cc/paper/1861-algorithms-for-non-negative-matrix-factorization.pdf\n",
    "\n",
    "The problem is defined with two distances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sklearn version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lamjo_000\\Anaconda3\\envs\\python3\\lib\\site-packages\\sklearn\\utils\\fixes.py:64: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if 'order' in inspect.getargspec(np.copy)[0]:\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "\n",
    "#Calculate predicted ratings with NMF, sklearn version\n",
    "def NMFsk(A,d=15):\n",
    "    A=np.array(A)\n",
    "    nmf = NMF(n_components=d)\n",
    "    P = nmf.fit_transform(A);\n",
    "    Q = nmf.components_;\n",
    "    euclidean = np.nansum((A-P @ Q)**2)\n",
    "    print(\"The euclidean distance is {d}\".format(d=euclidean))\n",
    "    return (P @ Q, P, Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The euclidean distance is 3863.5191437865\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[ 4.98710422,  4.99700359,  4.9799231 , ...,  0.96844825,\n",
       "          0.96433159,  0.97703689],\n",
       "        [ 4.96078961,  4.97063063,  4.95364629, ...,  0.97349256,\n",
       "          0.969329  ,  0.98210653],\n",
       "        [ 4.9916107 ,  5.00157827,  4.98451541, ...,  0.96776042,\n",
       "          0.9636541 ,  0.97650984],\n",
       "        ..., \n",
       "        [ 0.97326314,  0.97934396,  0.97095945, ...,  4.99118932,\n",
       "          4.96805857,  4.99666699],\n",
       "        [ 0.94419717,  0.95020161,  0.94202404, ...,  4.99349694,\n",
       "          4.97033802,  4.99866406],\n",
       "        [ 0.98166033,  0.98782012,  0.97934669, ...,  4.99561073,\n",
       "          4.97250463,  5.00066251]]),\n",
       " array([[  3.21480623e-01,   8.86030454e-02,   1.14116996e-01, ...,\n",
       "           1.22270933e-01,   1.82399519e-02,   1.81582871e+00],\n",
       "        [  3.19851605e-01,   9.47086503e-02,   1.15329052e-01, ...,\n",
       "           1.26606564e-01,   1.67598404e-02,   1.80503008e+00],\n",
       "        [  3.20502709e-01,   9.20873469e-02,   1.21737178e-01, ...,\n",
       "           1.23775047e-01,   1.23805131e-02,   1.81883178e+00],\n",
       "        ..., \n",
       "        [  3.14964726e-01,   3.27156841e-01,   3.96244977e-01, ...,\n",
       "           1.38202002e-02,  -0.00000000e+00,   1.45299999e-02],\n",
       "        [  3.18285116e-01,   3.25840668e-01,   4.03171114e-01, ...,\n",
       "           7.30607750e-03,   7.79178304e-03,   2.94978138e-04],\n",
       "        [  3.18128318e-01,   3.29544956e-01,   4.04324488e-01, ...,\n",
       "           4.25472196e-03,   1.04386448e-02,   1.54699267e-02]]),\n",
       " array([[ 0.60005167,  0.60370891,  0.60268087, ...,  0.590084  ,\n",
       "          0.58413762,  0.5881246 ],\n",
       "        [ 0.15010115,  0.14864536,  0.14839133, ...,  0.01643793,\n",
       "          0.01953251,  0.017638  ],\n",
       "        [ 0.03228669,  0.03219848,  0.03528516, ...,  0.00722859,\n",
       "          0.00658753,  0.0064264 ],\n",
       "        ..., \n",
       "        [ 0.14164899,  0.14022658,  0.13895615, ...,  0.01714178,\n",
       "          0.02102642,  0.02511682],\n",
       "        [ 0.77458406,  0.76672582,  0.76407545, ...,  0.07849376,\n",
       "          0.07460536,  0.04906188],\n",
       "        [ 2.43614337,  2.44121394,  2.43050436, ...,  0.0219081 ,\n",
       "          0.02109737,  0.02586911]]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NMFsk(A,15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kullback-Leibler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Updates the matrices P and Q for an iteration\n",
    "def update(A, P, Q, PQ, A_over_PQ):\n",
    "    # equation (5)\n",
    "    Q *= (A_over_PQ.T @ P / P.sum(axis=0)).T\n",
    "    PQ = P @ Q\n",
    "    A_over_PQ = A / PQ\n",
    "    P *= (A_over_PQ @ Q.T) / Q.sum(axis=1)\n",
    "\n",
    "    PQ = P @ Q\n",
    "    P_over_PQ = A / PQ\n",
    "    return P, Q, PQ, A_over_PQ\n",
    "\n",
    "\n",
    "def NMFdiv(A, d=15, iterations=100):\n",
    "    n, m = A.shape\n",
    "    P = np.random.random(n * d).reshape(n, d) * 4 + 1\n",
    "    Q = np.random.random(d * m).reshape(d, m) * 4 + 1\n",
    "    PQ = P @ Q\n",
    "    A_over_PQ = A / PQ\n",
    "    for i in range(iterations):\n",
    "        P, Q, PQ, A_over_PQ = update(A, P, Q, PQ, A_over_PQ)\n",
    "        # equation (3)\n",
    "        divergence = np.nansum((A * np.log(A_over_PQ)) - A + PQ)\n",
    "    print(\"The Kullback–Leibler divergence is {d}\".format(d=divergence))\n",
    "    return(P @ Q, P, Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Kullback–Leibler divergence is 73913.48744363716\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[ 1.67882058,  1.65813213,  1.66926519, ...,  0.97066025,\n",
       "          0.96952884,  0.97039909],\n",
       "        [ 1.67330389,  1.66986557,  1.66482246, ...,  0.97629309,\n",
       "          0.98995033,  0.97195157],\n",
       "        [ 1.69297407,  1.67110203,  1.68002244, ...,  0.97156291,\n",
       "          0.96980872,  0.9687501 ],\n",
       "        ..., \n",
       "        [ 0.92854273,  0.93050316,  0.92376562, ...,  5.00414241,\n",
       "          4.98994518,  4.98654408],\n",
       "        [ 0.95063742,  0.94836182,  0.94463824, ...,  5.00965591,\n",
       "          4.99468908,  4.99151533],\n",
       "        [ 0.91812533,  0.93301208,  0.91054441, ...,  5.0010559 ,\n",
       "          4.99577333,  4.97748021]]),\n",
       " array([[  2.17872723e+00,   2.32525161e+00,   2.66910091e+00, ...,\n",
       "           1.28370873e+00,   4.03535124e+00,   9.10634129e-01],\n",
       "        [  2.12813424e+00,   2.44916128e+00,   2.75446933e+00, ...,\n",
       "           1.07615718e+00,   3.07314941e+00,   7.39383782e-01],\n",
       "        [  2.15121038e+00,   2.41391154e+00,   2.68271689e+00, ...,\n",
       "           1.07957434e+00,   4.13384074e+00,   9.26644182e-01],\n",
       "        ..., \n",
       "        [  2.60397457e+00,   1.25840954e+00,   4.17094328e+01, ...,\n",
       "           3.57332000e+00,   1.79798871e+00,   2.65322584e-02],\n",
       "        [  2.59428629e+00,   1.30242782e+00,   4.17636691e+01, ...,\n",
       "           3.56760203e+00,   1.93676366e+00,   2.28723685e-02],\n",
       "        [  2.53940085e+00,   1.47167092e+00,   4.17615379e+01, ...,\n",
       "           3.12176420e+00,   1.17082925e+00,   2.41797078e-02]]),\n",
       " array([[ 0.02027923,  0.01891649,  0.02076785, ...,  0.02374386,\n",
       "          0.02410907,  0.02516589],\n",
       "        [ 0.0268025 ,  0.02989016,  0.02208491, ...,  0.02672496,\n",
       "          0.02839652,  0.02382822],\n",
       "        [ 0.00524287,  0.00569809,  0.00467619, ...,  0.10984938,\n",
       "          0.10972991,  0.10908432],\n",
       "        ..., \n",
       "        [ 0.02094065,  0.01663455,  0.02773464, ...,  0.03001404,\n",
       "          0.02751545,  0.03421696],\n",
       "        [ 0.06417423,  0.04969829,  0.06155363, ...,  0.01980326,\n",
       "          0.01009375,  0.02336036],\n",
       "        [ 0.00944428,  0.01186794,  0.01040172, ...,  0.01064866,\n",
       "          0.00522608,  0.0080749 ]]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NMFdiv(A,15,101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Euclidean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update(A, P, Q):\n",
    "    # equation (6)\n",
    "    Q *= P.T @ A / (P.T @ P @ Q)\n",
    "    P *= (A @ Q.T) / (P @ Q @ Q.T)\n",
    "    return P, Q\n",
    "\n",
    "\n",
    "def NMFeuc(A, d, iterations=100):\n",
    "    n, m = A.shape\n",
    "    P = np.random.random(n * d).reshape(n, d) * 4 + 1\n",
    "    Q = np.random.random(d * m).reshape(d, m) * 4 + 1\n",
    "    for i in range(iterations):\n",
    "        P, Q = update(A, P, Q)\n",
    "        # equation (4)\n",
    "        PQ = P @ Q\n",
    "        euclidean = np.nansum((A-PQ)**2)\n",
    "    print(\"At iteration {i}, the euclidean distance is {d}\".format(i=i, d=euclidean))\n",
    "    return(P @ Q, P, Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At iteration 99, the euclidean distance is 26776.17872483564\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[ 1.07905251,  1.07739115,  1.07634101, ...,  0.98442668,\n",
       "          0.97913325,  0.98336137],\n",
       "        [ 1.12579474,  1.1272693 ,  1.12233953, ...,  0.99333828,\n",
       "          0.98417089,  0.98964348],\n",
       "        [ 1.13075565,  1.13184701,  1.12530959, ...,  0.9879241 ,\n",
       "          0.97897018,  0.98597305],\n",
       "        ..., \n",
       "        [ 1.1680637 ,  1.17456047,  1.16366485, ...,  4.99398119,\n",
       "          4.96591452,  4.98522202],\n",
       "        [ 1.16899827,  1.1762989 ,  1.16521949, ...,  4.99500436,\n",
       "          4.96708038,  4.98603153],\n",
       "        [ 1.16418785,  1.17032823,  1.15963821, ...,  5.00143165,\n",
       "          4.97327617,  4.99270848]]),\n",
       " array([[  2.82675219e+00,   8.88332494e-01,   2.17966194e+00, ...,\n",
       "           2.15114520e+00,   1.56733910e+00,   3.58178710e+00],\n",
       "        [  2.77765726e+00,   6.26690503e-01,   2.36940755e+00, ...,\n",
       "           2.14702507e+00,   1.53334372e+00,   3.24359226e+00],\n",
       "        [  2.65029813e+00,   4.19782749e-01,   2.76947723e+00, ...,\n",
       "           2.14646573e+00,   1.26824887e+00,   3.38366562e+00],\n",
       "        ..., \n",
       "        [  9.87891649e-01,   7.76992241e-03,   1.48075906e-01, ...,\n",
       "           4.07141892e-01,   1.06894917e+00,   8.15552926e+00],\n",
       "        [  9.79452450e-01,   1.82174348e-02,   2.45297879e-01, ...,\n",
       "           4.75606995e-01,   1.25622084e+00,   8.11357648e+00],\n",
       "        [  1.00721611e+00,   1.99721337e-02,   6.58465411e-02, ...,\n",
       "           4.58612158e-01,   8.95213975e-01,   8.24102755e+00]]),\n",
       " array([[ 0.02556099,  0.0247651 ,  0.02555151, ...,  0.01995592,\n",
       "          0.01924222,  0.01916433],\n",
       "        [ 0.00339546,  0.00486109,  0.00184648, ...,  0.00625186,\n",
       "          0.00300259,  0.00516426],\n",
       "        [ 0.03439087,  0.03718546,  0.03128469, ...,  0.01496383,\n",
       "          0.01289071,  0.01621669],\n",
       "        ..., \n",
       "        [ 0.02084019,  0.02082002,  0.0206298 , ...,  0.01700006,\n",
       "          0.01733589,  0.01702694],\n",
       "        [ 0.01514682,  0.01441839,  0.01758441, ...,  0.02217023,\n",
       "          0.022956  ,  0.02099179],\n",
       "        [ 0.02021282,  0.0181213 ,  0.02112202, ...,  0.02478451,\n",
       "          0.02510291,  0.02479485]]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NMFeuc(A,15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data from MovieLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_User</th>\n",
       "      <th>ID_Movie</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>874965758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>876893171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>878542960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>876893119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>889751712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID_User  ID_Movie  Rating       Time\n",
       "0        1         1       5  874965758\n",
       "1        1         2       3  876893171\n",
       "2        1         3       4  878542960\n",
       "3        1         4       3  876893119\n",
       "4        1         5       3  889751712"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading dataframes\n",
    "\n",
    "import pandas\n",
    "dfDirectory = \"C:\\\\Users\\\\lamjo_000\\\\Google Drive\\\\Stat App\\\\Data\\\\\"\n",
    "\n",
    "dataframeTrain = pandas.read_csv(dfDirectory + \"u1base.base\", sep=\"\\t\")\n",
    "dataframeTest = pandas.read_csv(dfDirectory + \"u1test.test\", sep=\"\\t\")\n",
    "\n",
    "#Shape of the dataframe :\n",
    "#for each user (column 0)\n",
    "#   for each film (column 1)\n",
    "#        rating of the film according to the user (column 2)\n",
    "dataframeTrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nbUsers = 943\n",
    "nbFilms = 1682\n",
    "\n",
    "#Creating the corresponding matrix\n",
    "def dfToArray(dataframe, nbUsers = 943, nbFilms = 1682):\n",
    "    # Deleting variable time if it has not been deleted yet.\n",
    "    try:\n",
    "        del dataframe[\"Time\"]\n",
    "    except:\n",
    "        pass\n",
    "    ratings = np.zeros((nbUsers,nbFilms))\n",
    "    for i in range(dataframe.shape[0]):\n",
    "        #ratings[user][film] = rating\n",
    "        #indices of users and films start from 1, not from 0.\n",
    "        ratings[dataframe.ix[i][0]-1][dataframe.ix[i][1]-1] = int(dataframe.ix[i][2])\n",
    "    return(ratings)\n",
    "\n",
    "#Dictionary with key: matrix line; content: marked film id\n",
    "#{user : [films rated by user]}\n",
    "def ratedFilms(ratings):\n",
    "    ratedDict = {}\n",
    "    for i in range(ratings.shape[0]):\n",
    "        ratedDict[i]=[]\n",
    "        for k in range(ratings.shape[1]):\n",
    "            if ratings[i][k] != 0:\n",
    "                ratedDict[i].append(k)\n",
    "    return(ratedDict)\n",
    "\n",
    "# Dictionary with predicted marks\n",
    "def roundDown(x):\n",
    "    if x < 1.5:\n",
    "        return(1)\n",
    "    elif x >= 4.5:\n",
    "        return(5)\n",
    "    else:\n",
    "        return(round(x))\n",
    "\n",
    "#Keep predicted values for (user,film) where the couple exists in the test dataframe.\n",
    "def roundRatings(ratedTest,ratings,roundIt):\n",
    "    if roundIt:\n",
    "        applyFct = roundDown\n",
    "    else:\n",
    "        applyFct = lambda x : x\n",
    "    roundedRatings = {}\n",
    "    for user in ratedTest:\n",
    "        for film in ratedTest[user]:\n",
    "            roundedRatings[(user,film)] =  applyFct(ratings[user][film])\n",
    "    return roundedRatings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create arrays\n",
    "ratingsTrain = dfToArray(dataframeTrain)\n",
    "ratingsTest = dfToArray(dataframeTest)        \n",
    "\n",
    "#We pull out every empty column in Train.\n",
    "#Here is a list of columns with only 0s\n",
    "#Reverse, so that the index isn't changed during the process of deleting the columns (start from the end)\n",
    "matrix_sum = reversed(np.where(np.nansum(ratingsTrain,axis=0) == 0)[0])\n",
    "        \n",
    "for i in matrix_sum:\n",
    "    ratingsTrain = np.delete(ratingsTrain, i, 1)\n",
    "    ratingsTest = np.delete(ratingsTest, i, 1) #We don't want to lose the indices in test.\n",
    "            \n",
    "ratedTest = ratedFilms(ratingsTest)\n",
    "        \n",
    "# Create dictionary with real ratings\n",
    "ratingsTestDic = roundRatings(ratedTest, ratingsTest, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For data with missing values, Matrix factorization is not enough. We need Matrix Completion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Completion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check accuracy of predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Comparison with test set\n",
    "def calculateAccuracy(roundedRatings,ratingsTestDic):\n",
    "    errorMax = 4 #Maximum distance to true value is 4.\n",
    "    error = 0\n",
    "    for coupleUF in roundedRatings:\n",
    "        error += abs(roundedRatings[coupleUF] - ratingsTestDic[coupleUF])\n",
    "    return 1 - error/(errorMax*len(ratingsTestDic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average, that is naive prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We change missing data to the average per user. This can be used as a naive prediction of the missing data, and thus as a benchmark for the accuracy of the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Mean per user and corresponding dictionary\n",
    "#NMF averaged\n",
    "def averageUser(ratings):\n",
    "    rowMean = np.average(ratings, axis=1, weights = ratings.astype(bool))\n",
    "    return(rowMean)\n",
    "\n",
    "#Creating matrix, replacing 0s with means\n",
    "def replace0s(ratings,rowMean):\n",
    "    noZeroRatings = ratings.copy()\n",
    "    inds = np.where(ratings == 0)\n",
    "    noZeroRatings[inds]=np.take(rowMean,inds[0])\n",
    "    return(noZeroRatings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.793820112179\n"
     ]
    }
   ],
   "source": [
    "# Create list of average ratings by user\n",
    "rowMean = averageUser(ratingsTrain)\n",
    "ratings = replace0s(ratingsTrain, rowMean)\n",
    "\n",
    "# Create dictionary with predicted ratings\n",
    "ratings = roundRatings(ratedTest,ratings,True)\n",
    "\n",
    "\n",
    "# Calculate accuracy\n",
    "print(calculateAccuracy(ratings,ratingsTestDic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average, then NMF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another possibility is to apply NMF, once the missing data have been replaced by the average by user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At iteration 999, the euclidean distance is 73816.10639638393\n",
      "0.80462489984\n"
     ]
    }
   ],
   "source": [
    "# Create list of average ratings by user\n",
    "rowMean = averageUser(ratingsTrain)\n",
    "ratings = replace0s(ratingsTrain, rowMean)\n",
    "\n",
    "# Create new matrix with NMF for euclidean distance.\n",
    "ratings,P,Q = NMFeuc(ratings,9,1000)\n",
    "\n",
    "# Create dictionary with predited ratings\n",
    "ratings = roundRatings(ratedTest,ratings,True)\n",
    "\n",
    "# Calculate accuracy\n",
    "print(calculateAccuracy(ratings,ratingsTestDic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted Non Negative Matrix Factorization (WNMF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://www.siam.org/meetings/sdm06/proceedings/059zhangs2.pdf 3.2\n",
    "\n",
    "The only formalized version that was found is for the euclidean distance. Thus, starting from now, we won't consider the Kullback–Leibler divergence anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update(weightedA, P, Q, Weights):\n",
    "    # equation (5)\n",
    "    weightedPQ = Weights * (P @ Q)\n",
    "    P *= (weightedA @ Q.T) / (weightedPQ @ Q.T)\n",
    "    weightedPQ = Weights * (P @ Q)\n",
    "    Q *= (P.T @ weightedA) / (P.T @ weightedPQ)\n",
    "    return P, Q\n",
    "\n",
    "\n",
    "def WNMF(A, d, iterations=100):\n",
    "    n, m = A.shape\n",
    "    P = np.random.random(n * d).reshape(n, d) * 4 + 1\n",
    "    Q = np.random.random(d * m).reshape(d, m) * 4 + 1\n",
    "    Weights = A.copy()\n",
    "    Weights[Weights != 0] = 1\n",
    "    weightedA = A # =Weights * A \n",
    "    for i in range(iterations):\n",
    "        P, Q = update(weightedA, P, Q, Weights)\n",
    "        PQ = P @ Q\n",
    "        weightedPQ = Weights * PQ\n",
    "        euclidean = np.nansum((weightedA-weightedPQ)**2)\n",
    "    print(\"The euclidean distance is {d}\".format(d=euclidean))\n",
    "    return(P @ Q, P, Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The euclidean distance is 39390.840571025525\n",
      "0.806891025641\n"
     ]
    }
   ],
   "source": [
    "# Create new matrix with WNMF.\n",
    "ratings,P,Q = WNMF(ratingsTrain,9,1000)\n",
    "\n",
    "# Create dictionary with predicted ratings\n",
    "ratings = roundRatings(ratedTest,ratings,True)\n",
    "\n",
    "# Calculate accuracy\n",
    "print(calculateAccuracy(ratings,ratingsTestDic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import heapq\n",
    "#Take 2 dictionaries to compare and find the TPR\n",
    "def calculateTPR(ratings,ratingsTestDic,NBest=5, nbUsers=943):\n",
    "    TPRlist = []\n",
    "    for user in range(nbUsers):\n",
    "        TPRuser = 0\n",
    "        ratingsUser = {}\n",
    "        for (userT,film) in ratingsTestDic:\n",
    "            if userT == user: # select films from test data\n",
    "                ratingsUser[film] = ratingsTestDic[(user,film)]\n",
    "        #Take NBest highest ratings of user       \n",
    "        NBestlist = heapq.nlargest(NBest, ratingsUser, key=ratingsUser.get)\n",
    "        for best in NBestlist:\n",
    "            #calculate TPR with a maximum distance of 1 (see report)\n",
    "            if abs(ratingsTestDic[(user,best)] - roundDown(ratings[(user,best)])) < 2:\n",
    "                TPRuser += 1\n",
    "        #If there are enough films in test for the user        \n",
    "        if len(ratingsUser) >= NBest:\n",
    "            TPRlist.append(TPRuser)\n",
    "    TPR = sum(TPRlist)/(NBest*float(len(TPRlist)))\n",
    "    #return average TPR\n",
    "    return TPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "The euclidean distance is 66394.66103688107\n",
      "2\n",
      "The euclidean distance is 58886.93423551466\n",
      "3\n",
      "The euclidean distance is 54692.842714007675\n",
      "4\n",
      "The euclidean distance is 51104.47555297158\n",
      "5\n",
      "The euclidean distance is 48199.10356696432\n",
      "6\n",
      "The euclidean distance is 45809.24398149295\n",
      "7\n",
      "The euclidean distance is 43249.26827791491\n",
      "8\n",
      "The euclidean distance is 41330.46161075259\n",
      "9\n",
      "The euclidean distance is 39244.71494303611\n",
      "10\n",
      "The euclidean distance is 37455.751761842366\n",
      "11\n",
      "The euclidean distance is 35716.07306467262\n",
      "12\n",
      "The euclidean distance is 34492.998118453856\n",
      "13\n",
      "The euclidean distance is 33043.19607312435\n",
      "14\n",
      "The euclidean distance is 31465.850770441015\n",
      "15\n",
      "The euclidean distance is 30132.773037978288\n",
      "16\n",
      "The euclidean distance is 28998.15907659244\n",
      "17\n",
      "The euclidean distance is 27647.04054110751\n",
      "18\n",
      "The euclidean distance is 26677.155105400645\n",
      "19\n",
      "The euclidean distance is 25680.18240875936\n",
      "20\n",
      "The euclidean distance is 24836.552412079982\n",
      "21\n",
      "The euclidean distance is 23862.890637423847\n",
      "22\n",
      "The euclidean distance is 22785.221094192653\n",
      "23\n",
      "The euclidean distance is 21951.02156496721\n",
      "24\n",
      "The euclidean distance is 21060.171614585957\n",
      "25\n",
      "The euclidean distance is 20397.057333848745\n",
      "26\n",
      "The euclidean distance is 19615.396034930032\n",
      "27\n",
      "The euclidean distance is 18804.519014361973\n",
      "28\n",
      "The euclidean distance is 18207.15687858291\n",
      "29\n",
      "The euclidean distance is 17639.63177459938\n",
      "30\n",
      "The euclidean distance is 16917.929500444785\n",
      "31\n",
      "The euclidean distance is 16296.687331645977\n",
      "32\n",
      "The euclidean distance is 15884.061936496213\n",
      "33\n",
      "The euclidean distance is 15227.866178407015\n",
      "34\n",
      "The euclidean distance is 14856.63378243241\n",
      "35\n",
      "The euclidean distance is 14164.675228363889\n",
      "36\n",
      "The euclidean distance is 13819.271474730916\n",
      "37\n",
      "The euclidean distance is 13262.955835873456\n",
      "38\n",
      "The euclidean distance is 12820.681795315546\n",
      "39\n",
      "The euclidean distance is 12518.206032901684\n",
      "40\n",
      "The euclidean distance is 11957.746424538795\n",
      "41\n",
      "The euclidean distance is 11471.99244691612\n",
      "42\n",
      "The euclidean distance is 11093.563751761505\n",
      "43\n",
      "The euclidean distance is 10655.621736545952\n",
      "44\n",
      "The euclidean distance is 10240.043184405335\n",
      "45\n",
      "The euclidean distance is 9964.077848958566\n",
      "46\n",
      "The euclidean distance is 9639.066063219436\n",
      "47\n",
      "The euclidean distance is 9488.293780527656\n",
      "48\n",
      "The euclidean distance is 9111.548875848217\n",
      "49\n",
      "The euclidean distance is 8700.347946545446\n",
      "50\n",
      "The euclidean distance is 8442.8615362627\n",
      "51\n",
      "The euclidean distance is 8075.533568345558\n",
      "52\n",
      "The euclidean distance is 7854.475779578107\n",
      "53\n",
      "The euclidean distance is 7685.2806260143725\n",
      "54\n",
      "The euclidean distance is 7255.898277893198\n",
      "55\n",
      "The euclidean distance is 7139.094979910189\n",
      "56\n",
      "The euclidean distance is 6785.169446329201\n",
      "57\n",
      "The euclidean distance is 6533.114096059941\n",
      "58\n",
      "The euclidean distance is 6404.03079889714\n",
      "59\n",
      "The euclidean distance is 6139.2855887685055\n",
      "60\n",
      "The euclidean distance is 6041.793094526531\n",
      "61\n",
      "The euclidean distance is 5846.743266664975\n",
      "62\n",
      "The euclidean distance is 5582.407655369764\n",
      "63\n",
      "The euclidean distance is 5420.775541948679\n",
      "64\n",
      "The euclidean distance is 5182.532798655883\n",
      "65\n",
      "The euclidean distance is 5059.966430819337\n",
      "66\n",
      "The euclidean distance is 4884.744825881725\n",
      "67\n",
      "The euclidean distance is 4691.876757268883\n",
      "68\n",
      "The euclidean distance is 4511.701880474616\n",
      "69\n",
      "The euclidean distance is 4364.818012377803\n",
      "70\n",
      "The euclidean distance is 4268.88545002718\n",
      "71\n",
      "The euclidean distance is 4095.5008360760066\n",
      "72\n",
      "The euclidean distance is 3889.637920864316\n",
      "73\n",
      "The euclidean distance is 3834.4043115305776\n",
      "74\n",
      "The euclidean distance is 3674.351532969727\n",
      "75\n",
      "The euclidean distance is 3559.280635953905\n",
      "76\n",
      "The euclidean distance is 3461.2485727958583\n",
      "77\n",
      "The euclidean distance is 3364.523790898849\n",
      "78\n",
      "The euclidean distance is 3185.9174400460574\n",
      "79\n",
      "The euclidean distance is 3107.8895644643926\n",
      "80\n",
      "The euclidean distance is 2997.4157187808464\n",
      "81\n",
      "The euclidean distance is 2924.279759607748\n",
      "82\n",
      "The euclidean distance is 2779.163700635986\n",
      "83\n",
      "The euclidean distance is 2718.320894253698\n",
      "84\n",
      "The euclidean distance is 2572.0314402147283\n",
      "85\n",
      "The euclidean distance is 2472.0405924820525\n",
      "86\n",
      "The euclidean distance is 2389.9693470025627\n",
      "87\n",
      "The euclidean distance is 2327.544874007609\n",
      "88\n",
      "The euclidean distance is 2243.479026467054\n",
      "89\n",
      "The euclidean distance is 2211.7373920696277\n",
      "90\n",
      "The euclidean distance is 2106.9092823153774\n",
      "91\n",
      "The euclidean distance is 2120.512369567054\n",
      "92\n",
      "The euclidean distance is 1934.7426043954351\n",
      "93\n",
      "The euclidean distance is 1898.47417365509\n",
      "94\n",
      "The euclidean distance is 1830.2589945394432\n",
      "95\n",
      "The euclidean distance is 1770.2193645767686\n",
      "96\n",
      "The euclidean distance is 1710.617088855401\n",
      "97\n",
      "The euclidean distance is 1622.2168186871008\n",
      "98\n",
      "The euclidean distance is 1582.3964564141925\n",
      "99\n",
      "The euclidean distance is 1523.6584744979707\n",
      "100\n",
      "The euclidean distance is 1453.6017610205254\n"
     ]
    }
   ],
   "source": [
    "#Figure 2\n",
    "mat = [[\"d\",\"TPR\"]]\n",
    "for d in range(1,101):\n",
    "    print(d)\n",
    "    # Create new matrix, applying the WNMF\n",
    "    ratings,P,Q = WNMF(ratingsTrain,d,1000)\n",
    "\n",
    "    # Create dictionary with predicted ratings\n",
    "    # Don't round the ratings now, so that a ranking of the ratings may be possible\n",
    "    roundedRatings = roundRatings(ratedTest,ratings,False)\n",
    "\n",
    "    # Calculate de TPR\n",
    "    mat += [[d,calculateTPR(roundedRatings,ratingsTestDic)]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clusterisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Empty 93% of data\n",
    "#We need to keep at least one non-missing value per row and per column. \n",
    "def addMissing(data):\n",
    "    nbRows, nbCols = data.shape\n",
    "    #Goal : create an array of 0s and 1s.\n",
    "    #Then, once we multiply it with our original data elementwise, we only keep data where there was a 1.\n",
    "    wCleaner = np.zeros((nbRows, nbCols))\n",
    "    \n",
    "    #Keep at least a 1 in each row\n",
    "    l = np.random.choice(range(nbCols), nbRows)\n",
    "    for i in range(nbRows):\n",
    "        wCleaner[i][l[i]] = 1\n",
    "    \n",
    "    #Keep at least a 1 in each column\n",
    "    l = np.random.choice(range(nbRows), nbCols)\n",
    "    for j in range(nbCols):\n",
    "        wCleaner[l[j]][j] = 1\n",
    "        \n",
    "    #Put 1s in random positons    \n",
    "    l = np.random.choice(range(nbRows*nbCols), int(0.07 * nbRows*nbCols), False)\n",
    "    for i in range(nbRows):\n",
    "        for j in range(nbCols):\n",
    "            if nbCols*i+j in l:\n",
    "                wCleaner[i][j] = 1\n",
    "    return (wCleaner * data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = addMissing(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kMeansApply(steps, nbSamples, nbFeatures, nbClusters, initialCenters, Matrix):#initialCenters = r or centerspp\n",
    "    centersClusters=np.zeros((nbSamples, nbFeatures))\n",
    "    centersClusters[:nbClusters,:] = Matrix[initialCenters,:]\n",
    "    usersClusters={}\n",
    "    for i in range(nbClusters):\n",
    "        usersClusters[i]=[]\n",
    "        \n",
    "    for j in range(steps):\n",
    "        # Find closest cluster to user\n",
    "        for i in range(nbSamples):\n",
    "            closest=0\n",
    "            #find minimum for L2\n",
    "            for k in range(nbClusters):\n",
    "                if np.linalg.norm(np.array(centersClusters[k])-np.array(Matrix[i])) <= np.linalg.norm(np.array(centersClusters[closest])-np.array(Matrix[i])):\n",
    "                    closest=k\n",
    "                    \n",
    "            #if Matrix[i] (which is an array) not in usersClusters[closest]:\n",
    "            if not any((Matrix[i] == x).all() for x in usersClusters[closest]):\n",
    "                usersClusters[closest].append(Matrix[i])  \n",
    "    \n",
    "        #Change centers of clusters\n",
    "        #Reinitialize clusters\n",
    "        if j != steps-1:    \n",
    "            for i in range(nbClusters):\n",
    "                if usersClusters[i] != []:\n",
    "                    centersClusters[i]=np.sum(usersClusters[i],axis=0)/len(usersClusters[i])\n",
    "                    usersClusters[i]=[] \n",
    "    return (usersClusters,centersClusters)\n",
    "\n",
    "# Initialization : the centers of the clusters are samples at random.\n",
    "\n",
    "def kMeans(M, nbClusters, steps):\n",
    "    Matrix=np.array(M)\n",
    "    nbSamples, nbFeatures = Matrix.shape\n",
    "    \n",
    "    #Initialize centers of clusters\n",
    "    ##Generate nbClusters random integers in [0,nbSamples) without replacement\n",
    "    initialCenters = np.random.choice(nbSamples, nbClusters, replace=False)\n",
    "    usersClusters, centersClusters = kMeansApply(steps, nbSamples, nbFeatures, nbClusters, initialCenters, Matrix)\n",
    "        \n",
    "    return (usersClusters, centersClusters)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nbClusters = 15\n",
    "steps = 100\n",
    "(usersClusters,centersClusters)=kMeans(A, nbClusters, steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fill clusters with users thanks to labels.\n",
    "# Output : centers and indices of users associated with each center\n",
    "def orderLabels(Matrix, linkUserCluster):\n",
    "    associatedUsers = {}\n",
    "    centers = []\n",
    "    for cluster in linkUserCluster:\n",
    "        associatedUsers[cluster] = [user for user, clus in enumerate(linkUserCluster) if cluster == clus]\n",
    "    for cluster in associatedUsers:\n",
    "        l = []\n",
    "        for user in associatedUsers[cluster]:\n",
    "            l.append(Matrix[user])\n",
    "        centers.append(np.sum(l, axis=0)/len(l))\n",
    "    return (centers,associatedUsers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sklearn version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering done\n",
      "{0: [438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476], 1: [205, 207, 218, 223, 231, 253, 259, 263, 270, 273, 276, 326, 332, 346, 347, 374, 388, 391], 2: [23, 25, 30, 35, 43, 44, 45, 46, 51, 52, 54, 55, 59, 63, 65, 67, 69, 71, 72, 75, 76, 77, 79, 83, 85, 87, 88, 90, 91, 92, 93, 107, 109, 111, 113, 114, 117, 123, 125, 127, 132, 138, 139, 140, 144, 146, 147, 148, 151, 152, 153, 158, 159, 160, 164, 166, 167, 171, 173, 178, 180, 181, 185, 186, 188, 190, 195], 3: [520, 523, 533, 537, 538, 539, 540, 553, 557, 561, 565, 566, 572, 586, 588, 589, 591, 597, 599, 603, 606, 608, 613, 615, 622, 623, 624, 626, 630, 631, 632, 633, 644, 645, 653, 655, 658, 659, 665, 666, 670, 671], 4: [781, 782, 785, 789, 806, 810, 813, 816, 820, 835, 844, 846, 856, 863, 874, 878, 886, 903], 5: [675, 676, 678, 679, 680, 681, 682, 685, 686, 687, 689, 692, 693, 694, 695, 696, 698, 699, 702, 703, 704, 705, 708, 710, 713, 717, 720, 721, 725, 726, 727, 728, 729, 730, 731, 732, 735, 736, 740, 741, 742, 744, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 758, 759, 760], 6: [926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942], 7: [477, 478, 479, 480, 481], 8: [904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925], 9: [424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437], 10: [392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423], 11: [502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516], 12: [496, 497, 498, 499, 500, 501], 13: [482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495], 14: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18], 15: [20, 24, 26, 29, 33, 34, 36, 37, 40, 41, 48, 49, 56, 57, 58, 61, 62, 66, 68, 70, 73, 78, 81, 84, 86, 89, 96, 97, 102, 105, 106, 112, 115, 118, 120, 124, 128, 130, 131, 133, 142, 149, 150, 155, 156, 157, 162, 165, 169, 174, 175, 179, 182, 183, 189, 192, 193, 194, 196, 199], 16: [677, 683, 684, 688, 690, 691, 697, 700, 701, 706, 707, 709, 711, 712, 714, 715, 716, 718, 719, 722, 723, 724, 733, 734, 737, 738, 739, 743, 745, 746, 757], 17: [200, 233, 266, 268, 269, 271, 278, 282, 287, 289, 292, 296, 303, 310, 312, 314, 315, 323, 325, 327, 341, 357, 358, 362, 373, 376, 378, 390], 18: [22, 27, 28, 31, 32, 39, 42, 47, 50, 53, 60, 64, 74, 80, 82, 94, 95, 98, 99, 100, 103, 104, 110, 119, 122, 126, 134, 136, 141, 143, 145, 154, 163, 172, 176, 184, 187, 191, 198], 19: [201, 203, 206, 210, 212, 219, 221, 226, 228, 229, 232, 235, 236, 240, 244, 249, 250, 251, 255, 260, 261, 272, 274, 280, 281, 290, 304, 308, 319, 321, 324, 330, 331, 334, 335, 337, 339, 340, 348, 349, 355, 368, 371, 375, 377, 379, 381, 382, 383, 384, 386], 20: [202, 213, 230, 234, 248, 256, 264, 283, 284, 285, 293, 294, 297, 309, 318, 328, 336, 338, 345, 354, 356, 364, 367, 369, 370, 385], 21: [531, 544, 551, 563, 573, 579, 584, 592, 616, 625, 636, 641, 642, 643, 646, 651, 657, 673, 674], 22: [521, 546, 549, 552, 559, 560, 574, 576, 595, 601, 604, 618, 621, 629, 637, 656, 667], 23: [204, 208, 209, 211, 214, 215, 216, 217, 220, 222, 224, 225, 227, 237, 238, 239, 241, 242, 243, 245, 246, 247, 252, 254, 257, 258, 262, 265, 267, 275, 277, 279, 286, 288, 291, 295, 298, 299, 300, 301, 302, 305, 306, 307, 311, 313, 316, 317, 320, 322, 329, 333, 342, 343, 344, 350, 351, 352, 353, 359, 360, 361, 363, 365, 366, 372, 380, 387, 389], 24: [517, 518, 519, 522, 524, 525, 526, 527, 528, 529, 530, 532, 534, 535, 536, 541, 542, 543, 545, 547, 548, 550, 554, 555, 556, 558, 562, 564, 567, 568, 569, 570, 571, 575, 577, 578, 580, 581, 582, 583, 585, 587, 590, 593, 594, 596, 598, 600, 602, 605, 607, 609, 610, 611, 612, 614, 617, 619, 620, 627, 628, 634, 635, 638, 639, 640, 647, 648, 649, 650, 652, 654, 660, 661, 662, 663, 664, 668, 669, 672], 25: [764, 772, 773, 783, 805, 808, 823, 825, 838, 896, 899], 26: [766, 797, 798, 814, 824, 829, 831, 843, 860, 869, 871, 875, 876, 877], 27: [762, 763, 767, 768, 769, 770, 775, 778, 779, 780, 784, 786, 787, 788, 792, 793, 795, 799, 801, 804, 807, 812, 815, 817, 822, 827, 828, 830, 832, 834, 836, 837, 840, 842, 845, 847, 848, 851, 853, 854, 855, 857, 858, 859, 865, 868, 870, 873, 880, 881, 883, 887, 889, 891, 892, 894, 895, 897, 898, 900], 28: [19, 21, 38, 101, 108, 116, 121, 129, 135, 137, 161, 168, 170, 177, 197], 29: [761, 765, 771, 774, 776, 777, 790, 791, 794, 796, 800, 802, 803, 809, 811, 818, 819, 821, 826, 833, 839, 841, 849, 850, 852, 861, 862, 864, 866, 867, 872, 879, 882, 884, 885, 888, 890, 893, 901, 902]}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import cluster\n",
    "#Figure 3\n",
    "# Number of clusters\n",
    "nbClusters=30\n",
    "\n",
    "# Clusterize\n",
    "kmeansAlg = cluster.KMeans(n_clusters=nbClusters, random_state=0).fit(A)\n",
    "linkUserCluster = kmeansAlg.predict(A) #list which associates a user to their closest cluster [index of cluster]\n",
    "print(\"Clustering done\")\n",
    "\n",
    "(centers,associatedUsers) = orderLabels(ratingsTrain,linkUserCluster)\n",
    "\n",
    "print(associatedUsers) #{index cluster : [user in cluster]}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "our version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Figure 3\n",
    "# Initalize for kmeans++\n",
    "def kmeansInit(Matrix, nbClusters):\n",
    "    #nbClusters the number of clusters\n",
    "    \n",
    "    check = True\n",
    "    while check:\n",
    "\n",
    "        #nbSamples the number of individuals, nbFeatures the number of films\n",
    "        nbSamples, nbFeatures = Matrix.shape\n",
    "\n",
    "        #Calculate norm 2 for each user\n",
    "        usersL2 = np.linalg.norm(Matrix, 2, axis=1)\n",
    "\n",
    "        #Create matrix of barycenters and list of barycenters\n",
    "        centers = np.empty((nbClusters, nbFeatures))\n",
    "        centersID = np.empty(nbClusters,dtype=int)\n",
    "\n",
    "        #Choose the first barycenter at random\n",
    "        centerID = np.random.randint(nbSamples)\n",
    "        centersID[0] = centerID\n",
    "        centers[0]=Matrix[centerID]\n",
    "\n",
    "        #Initialize matrix of squared distances\n",
    "        distSq = np.empty((nbClusters-1,nbSamples))\n",
    "\n",
    "        #Initialize list of smallest squared distances\n",
    "        closestDistSq = np.empty(nbSamples)\n",
    "\n",
    "        #Initialize list of smallest cumulated squared distances\n",
    "        aggregateClosestDistSq = np.empty(nbSamples)\n",
    "\n",
    "        #Choose other barycenters\n",
    "        for iter1 in range(nbClusters-1):\n",
    "            #Update matrix of distances\n",
    "            distSq[iter1] = (np.linalg.norm(Matrix - (np.array([centers[iter1]]).T @ np.ones((1,nbSamples))).T, 2, axis=1))**2\n",
    "\n",
    "            #Update list of smallest distances\n",
    "            closestDistSq = distSq.min(axis=0)\n",
    "\n",
    "            #Update list of smallest cumulated distances\n",
    "            aggregateClosestDistSq[0] = closestDistSq[0]\n",
    "            for iter2 in range(len(closestDistSq)-1):\n",
    "                aggregateClosestDistSq[iter2 +1] = closestDistSq[iter2 +1] + aggregateClosestDistSq[iter2]\n",
    "\n",
    "            #Choose a random real number between 0 and the potential\n",
    "            #Choose the new center according to a probability proportional to the squared distance between the considered point and the former point.\n",
    "            rand_nb = np.random.random() * aggregateClosestDistSq[-1]\n",
    "\n",
    "            #Choose barycenter\n",
    "            centerID = nbSamples - 1\n",
    "            while rand_nb < aggregateClosestDistSq[centerID - 1] and centerID > 0:\n",
    "                centerID -= 1\n",
    "\n",
    "            #Update centers and centers_id\n",
    "            centersID[iter1 + 1] = centerID\n",
    "            centers[iter1 + 1] = Matrix[centerID]\n",
    "\n",
    "        #In case of probability=0 or the same barycenter is chosen multiple times\n",
    "        if len(set(centersID)) == nbClusters:\n",
    "            check = False\n",
    "\n",
    "    #returns indices (between 0 and 942) of kept barycenters    \n",
    "    return centersID\n",
    "\n",
    "\n",
    "#kmeans++\n",
    "#returns a dictionary with applied partitioning\n",
    "def kmeansPP(M, nbClusters, steps):\n",
    "    Matrix=np.array(M)\n",
    "    nbUsers, nbFilms = Matrix.shape\n",
    "    initialCenters = kmeansInit(Matrix, nbClusters)\n",
    "    \n",
    "    usersClusters, centersClusters = kMeansApply(steps, nbUsers, nbFilms, nbClusters, initialCenters, Matrix)\n",
    "        \n",
    "    return (usersClusters,centersClusters)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The clustering is not as good as expected when you apply kmeans on data with missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering done\n",
      "{0: [125], 1: [480, 481, 676, 677, 678, 679, 680, 681, 683, 684, 686, 687, 688, 689, 690, 691, 693, 695, 696, 697, 699, 701, 702, 703, 704, 705, 706, 708, 709, 710, 713, 714, 715, 716, 717, 718, 720, 721, 723, 724, 725, 726, 728, 729, 733, 734, 735, 736, 737, 739, 741, 742, 743, 744, 747, 749, 750, 751, 752, 754, 755, 756, 757, 758, 927, 932], 2: [71], 3: [30, 32, 33, 35, 38, 39, 43, 45, 46, 47, 51, 52, 60, 62, 63, 65, 69, 73, 75, 85, 90, 92, 93, 97, 98, 107, 108, 111, 112, 115, 116, 119, 120, 126, 127, 134, 136, 149, 150, 157, 159, 161, 170, 171, 172, 174, 177, 179, 182, 185, 190, 196, 197, 199], 4: [31], 5: [147], 6: [928], 7: [19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 34, 37, 41, 42, 44, 48, 49, 50, 53, 54, 55, 56, 57, 58, 59, 61, 64, 66, 68, 70, 72, 74, 76, 77, 78, 79, 80, 81, 82, 83, 84, 86, 87, 88, 89, 91, 94, 95, 96, 99, 100, 101, 102, 103, 104, 105, 106, 109, 110, 113, 114, 117, 118, 121, 122, 123, 124, 128, 129, 130, 131, 132, 133, 135, 137, 138, 140, 141, 142, 143, 144, 145, 146, 148, 151, 152, 153, 154, 155, 156, 158, 163, 164, 165, 166, 167, 169, 173, 175, 176, 178, 180, 181, 183, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 198], 8: [727], 9: [162], 10: [626], 11: [517, 518, 520, 521, 522, 523, 524, 525, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 558, 559, 560, 561, 562, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 588, 589, 590, 591, 592, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 609, 610, 611, 612, 613, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 666, 668, 669, 670, 671, 672, 673, 674], 12: [40], 13: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 28, 36, 67, 139, 160, 168, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 519, 526, 557, 563, 586, 587, 593, 608, 614, 665, 667, 675, 682, 685, 692, 694, 698, 700, 707, 711, 712, 719, 722, 730, 731, 732, 738, 740, 745, 746, 748, 753, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 929, 930, 931, 933, 934, 935, 936, 937, 939, 940, 941, 942], 14: [938]}\n"
     ]
    }
   ],
   "source": [
    "# Number of clusters\n",
    "nbClusters=15\n",
    "\n",
    "# Clustering\n",
    "kmeans = cluster.KMeans(n_clusters=nbClusters, random_state=0).fit(data)\n",
    "linkUserCluster = kmeans.predict(data)\n",
    "print(\"Clustering done\")\n",
    "\n",
    "(centers,associatedUsers) = orderLabels(data,linkUserCluster)\n",
    "\n",
    "print(associatedUsers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NMF, then K-means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we apply complete the data (using NMF for instance). It is already better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The euclidean distance is 365.5577611140053\n",
      "Clustering done\n",
      "{0: [930, 939], 1: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 395, 401, 402, 403, 404, 405, 407, 408, 409, 410, 411, 413, 415, 416, 419, 420, 421, 422, 424, 426, 427, 432, 433, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 479, 480, 483, 484, 487, 488, 489, 491, 492, 493, 494, 495, 496, 497, 498, 499, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 940], 2: [932], 3: [927, 933, 934, 935, 942], 4: [430, 431, 435, 436, 437], 5: [904, 931, 937, 938], 6: [481], 7: [19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199], 8: [392, 393, 394, 396, 397, 398, 399, 400, 412, 414, 417, 418, 423, 425, 429, 434, 482, 490], 9: [928], 10: [517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674], 11: [929, 936], 12: [406, 428, 485, 486, 500, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 941], 13: [477, 478], 14: [926]}\n"
     ]
    }
   ],
   "source": [
    "#Figure 4\n",
    "\n",
    "#Segmentation on the completed matrix\n",
    "\n",
    "# Create new matrix with WNMF.\n",
    "predicted,P,Q = WNMF(data,15,1000)\n",
    "\n",
    "# Apply clustering\n",
    "kmeans = cluster.KMeans(n_clusters=nbClusters, random_state=0).fit(predicted)\n",
    "linkUserCluster = kmeans.predict(predicted)\n",
    "print(\"Clustering done\")\n",
    "\n",
    "(centers,associatedUsers) = orderLabels(A,linkUserCluster)\n",
    "\n",
    "print(associatedUsers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, because of the curse of dimensionality, it could be even better if we apply it on the factor matrix of users in order to clusterize them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering done\n",
      "{0: [19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199], 1: [481], 2: [927, 933, 934, 935, 942], 3: [761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 941], 4: [904, 926, 931, 937, 938], 5: [430, 431, 435, 436, 437], 6: [928], 7: [517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674], 8: [932], 9: [477, 478], 10: [497, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 940], 11: [929, 936], 12: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 432, 433, 434, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925], 13: [930, 939], 14: [479, 480]}\n"
     ]
    }
   ],
   "source": [
    "#Figure 4\n",
    "\n",
    "#Segmentation on the completed matrix\n",
    "\n",
    "# Apply clustering\n",
    "kmeans = cluster.KMeans(n_clusters=nbClusters, random_state=0).fit(P)\n",
    "linkUserCluster = kmeans.predict(P)\n",
    "print(\"Clustering done\")\n",
    "\n",
    "(centers,associatedUsers) = orderLabels(P,linkUserCluster)\n",
    "\n",
    "print(associatedUsers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Basic functions to treat error\n",
    "#Normalize vector\n",
    "def normalized(a):\n",
    "    n = np.linalg.norm(a)\n",
    "    result = []\n",
    "    for i in range(len(a)):\n",
    "        result.append(a[i]/float(n))\n",
    "    return np.array(result)\n",
    "\n",
    "#Calculate error to learn k\n",
    "def learningk(Matrix,centers,associatedUsers):\n",
    "    result = 0\n",
    "    for cluster in associatedUsers:\n",
    "        for user in associatedUsers[cluster]:\n",
    "            result += np.linalg.norm(centers[cluster] - normalized(Matrix[user]))**2\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learn number of clusters of users and films"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lamjo_000\\Anaconda3\\envs\\python3\\lib\\site-packages\\sklearn\\decomposition\\nmf.py:532: UserWarning: Iteration limit reached during fit. Solving for W exactly.\n",
      "  warnings.warn(\"Iteration limit reached during fit. Solving for W exactly.\")\n"
     ]
    }
   ],
   "source": [
    "# Figure 5 Figure 6\n",
    "\n",
    "d=15\n",
    "\n",
    "# Get P and Q\n",
    "nmf = NMF(n_components=d)\n",
    "P = nmf.fit_transform(ratingsTrain)\n",
    "Q = nmf.components_\n",
    "Q = Q.T\n",
    "\n",
    "############################\n",
    "### Clustering on P\n",
    "############################\n",
    "\n",
    "#Get error depending on the number of clusters\n",
    "mat = [[\"nbClusters\",\"error\"]]\n",
    "\n",
    "for nbClusters in range(1,101):    \n",
    "    print(nbClusters)\n",
    "\n",
    "    # Clustering\n",
    "    kmeans = cluster.KMeans(n_clusters=nbClusters, random_state=0).fit(P)\n",
    "    linkUserCluster = kmeans.predict(P)\n",
    "    \n",
    "    #Get normalized centers and clusters\n",
    "    (centersUsers,associatedUsers)=orderLabels(P,linkUserCluster)\n",
    "    \n",
    "    centersUsers = np.array(list(map(normalized,centersUsers)))\n",
    "    \n",
    "    mat += [[nbClusters,learningk(P,centersUsers,associatedUsers)]]\n",
    "    \n",
    "\n",
    "############################\n",
    "### Clustering on Q\n",
    "############################\n",
    "  \n",
    "#Get error depending on number of clusters\n",
    "mat = [[\"nbClusters\",\"error\"]]\n",
    "\n",
    "for nbClusters in range(1,101):\n",
    "    \n",
    "    print(nbClusters)\n",
    "\n",
    "    # Clustering\n",
    "    kmeans = cluster.KMeans(n_clusters=nbClusters, random_state=0).fit(Q)\n",
    "    linkFilmCluster = kmeans.predict(Q)\n",
    "    \n",
    "    #Get normalized centers and clusters\n",
    "    (centersFilms,associatedFilms)=orderLabels(Q,linkFilmCluster)\n",
    "    \n",
    "    centersFilms = np.array(list(map(normalized,centersFilms)))\n",
    "    \n",
    "    mat += [[nbClusters,learningk(Q,centersFilms,associatedFilms)]]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison with metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get ages of users\n",
      "[24, 53, 23, 24, 33, 42, 57, 36, 29, 53, 39, 28, 47, 45, 49, 21, 30, 35, 40, 42, 26, 25, 30, 21, 39, 49, 40, 32, 41, 7, 24, 28, 23, 38, 20, 19, 23, 28, 41, 38, 33, 30, 29, 26, 29, 27, 53, 45, 23, 21, 28, 18, 26, 22, 37, 25, 16, 27, 49, 50, 36, 27, 31, 32, 51, 23, 17, 19, 24, 27, 39, 48, 24, 39, 24, 20, 30, 26, 39, 34, 21, 50, 40, 32, 51, 26, 47, 49, 43, 60, 55, 32, 48, 26, 31, 25, 43, 49, 20, 36, 15, 38, 26, 27, 24, 61, 39, 44, 29, 19, 57, 30, 47, 27, 31, 40, 20, 21, 32, 47, 54, 32, 48, 34, 30, 28, 33, 24, 36, 20, 59, 24, 53, 31, 23, 51, 50, 46, 20, 30, 49, 13, 42, 53, 31, 45, 40, 33, 35, 20, 38, 33, 25, 25, 32, 25, 57, 50, 23, 27, 50, 25, 49, 47, 20, 47, 37, 48, 52, 53, 48, 55, 56, 30, 26, 28, 20, 26, 15, 22, 26, 36, 33, 37, 53, 39, 26, 42, 32, 30, 33, 42, 29, 38, 42, 49, 55, 21, 30, 40, 27, 41, 25, 52, 47, 14, 39, 43, 33, 39, 66, 49, 33, 26, 35, 22, 22, 37, 32, 30, 19, 29, 19, 31, 51, 28, 46, 21, 29, 28, 48, 45, 38, 60, 37, 44, 49, 42, 39, 23, 26, 33, 33, 28, 22, 19, 28, 25, 25, 29, 28, 42, 26, 44, 23, 35, 17, 19, 21, 40, 28, 19, 41, 36, 26, 62, 23, 24, 31, 18, 51, 33, 50, 20, 38, 21, 35, 37, 33, 30, 15, 22, 28, 40, 25, 27, 21, 34, 11, 40, 19, 35, 24, 34, 31, 43, 29, 44, 29, 26, 24, 42, 19, 22, 23, 45, 25, 60, 40, 37, 32, 48, 41, 20, 31, 43, 22, 65, 38, 19, 49, 20, 21, 21, 48, 41, 22, 51, 48, 35, 33, 20, 47, 32, 45, 23, 37, 39, 35, 46, 17, 25, 43, 30, 28, 34, 18, 24, 68, 32, 61, 37, 25, 29, 25, 32, 26, 40, 22, 51, 22, 35, 20, 63, 29, 20, 17, 18, 24, 52, 36, 25, 24, 36, 17, 28, 22, 35, 44, 32, 33, 45, 42, 52, 36, 36, 33, 31, 44, 42, 23, 52, 19, 25, 43, 57, 17, 40, 25, 33, 46, 30, 37, 29, 22, 52, 29, 23, 48, 30, 34, 25, 55, 24, 39, 20, 27, 55, 37, 53, 38, 26, 64, 36, 19, 55, 51, 28, 27, 38, 24, 22, 27, 16, 24, 30, 27, 51, 23, 30, 50, 22, 35, 51, 21, 57, 30, 23, 23, 35, 16, 35, 18, 57, 48, 24, 33, 47, 22, 44, 15, 19, 48, 60, 32, 22, 29, 28, 60, 24, 10, 24, 29, 51, 30, 28, 23, 29, 30, 57, 73, 18, 29, 27, 44, 39, 22, 48, 55, 29, 43, 57, 22, 38, 29, 21, 20, 26, 42, 28, 22, 22, 50, 40, 27, 46, 18, 27, 23, 34, 22, 29, 43, 27, 53, 53, 24, 49, 22, 62, 19, 36, 50, 56, 27, 30, 33, 18, 47, 29, 30, 20, 43, 20, 45, 38, 36, 31, 53, 28, 19, 21, 33, 44, 27, 36, 50, 51, 42, 16, 25, 45, 58, 32, 29, 35, 30, 56, 69, 32, 23, 54, 39, 65, 40, 20, 24, 39, 34, 26, 34, 51, 68, 56, 33, 48, 36, 31, 32, 16, 37, 17, 44, 25, 69, 20, 26, 18, 21, 50, 57, 18, 31, 46, 25, 20, 23, 40, 22, 34, 19, 47, 21, 39, 33, 28, 49, 22, 13, 22, 46, 36, 37, 54, 38, 55, 27, 15, 17, 18, 17, 25, 50, 19, 27, 23, 24, 13, 46, 26, 18, 18, 35, 39, 22, 47, 30, 45, 42, 20, 24, 18, 39, 51, 27, 17, 40, 43, 20, 42, 65, 35, 31, 27, 50, 48, 26, 33, 31, 26, 28, 55, 26, 30, 25, 44, 35, 29, 37, 30, 21, 54, 51, 13, 34, 30, 20, 50, 20, 33, 44, 23, 42, 28, 32, 32, 31, 37, 25, 35, 34, 34, 43, 60, 26, 55, 25, 28, 44, 17, 51, 37, 26, 51, 21, 23, 56, 26, 21, 19, 22, 22, 42, 26, 21, 36, 24, 42, 37, 49, 24, 50, 26, 31, 21, 25, 25, 58, 19, 31, 41, 28, 44, 25, 29, 48, 30, 35, 35, 25, 25, 35, 31, 35, 42, 25, 19, 28, 33, 28, 24, 60, 56, 59, 44, 30, 26, 27, 20, 35, 17, 32, 27, 27, 31, 42, 70, 29, 39, 28, 26, 50, 20, 30, 46, 30, 63, 34, 31, 49, 20, 21, 30, 47, 32, 36, 18, 51, 29, 27, 31, 40, 22, 32, 30, 32, 44, 40, 49, 25, 22, 35, 70, 39, 27, 27, 41, 45, 50, 55, 40, 22, 14, 30, 32, 34, 19, 28, 59, 22, 37, 29, 27, 31, 44, 28, 23, 28, 48, 46, 21, 24, 34, 26, 44, 44, 36, 23, 38, 39, 45, 40, 35, 22, 64, 27, 29, 46, 15, 34, 18, 46, 49, 29, 53, 43, 35, 63, 18, 70, 38, 25, 17, 27, 25, 45, 24, 21, 30, 22, 31, 19, 48, 36, 24, 41, 30, 50, 33, 13, 39, 35, 49, 44, 30, 20, 14, 41, 24, 32, 51, 36, 25, 47, 31, 28, 30, 23, 32, 60, 38, 45, 28, 17, 27, 45, 25, 44, 50, 28, 37, 51, 27, 44, 50, 27, 22, 40, 25, 30, 20, 29, 21, 29, 18, 49, 23, 21, 44, 28, 60, 58, 28, 61, 42, 24, 48, 38, 26, 32, 20, 48, 22]\n",
      "Get genders of users\n",
      "[0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0]\n",
      "Get jobs of users\n",
      "['tec', 'oth', 'wri', 'tec', 'oth', 'exe', 'adm', 'adm', 'stu', 'law', 'oth', 'oth', 'edu', 'sci', 'edu', 'ent', 'pro', 'oth', 'lib', 'hom', 'wri', 'wri', 'art', 'art', 'eng', 'eng', 'lib', 'wri', 'pro', 'stu', 'art', 'stu', 'stu', 'adm', 'hom', 'stu', 'stu', 'oth', 'ent', 'sci', 'eng', 'adm', 'lib', 'tec', 'pro', 'mar', 'mar', 'adm', 'stu', 'wri', 'edu', 'stu', 'pro', 'exe', 'pro', 'lib', 'non', 'pro', 'edu', 'hea', 'eng', 'adm', 'mar', 'edu', 'edu', 'stu', 'stu', 'stu', 'eng', 'eng', 'sci', 'adm', 'stu', 'sci', 'ent', 'stu', 'tec', 'adm', 'adm', 'adm', 'stu', 'pro', 'oth', 'exe', 'edu', 'adm', 'adm', 'lib', 'adm', 'edu', 'mar', 'ent', 'exe', 'stu', 'adm', 'art', 'art', 'exe', 'stu', 'exe', 'stu', 'pro', 'stu', 'stu', 'eng', 'ret', 'sci', 'edu', 'oth', 'stu', 'eng', 'sal', 'exe', 'pro', 'eng', 'hea', 'stu', 'adm', 'pro', 'oth', 'lib', 'wri', 'art', 'stu', 'law', 'law', 'non', 'mar', 'mar', 'non', 'adm', 'oth', 'eng', 'pro', 'stu', 'oth', 'edu', 'doc', 'stu', 'stu', 'pro', 'oth', 'tec', 'pro', 'ent', 'art', 'lib', 'eng', 'mar', 'art', 'adm', 'edu', 'stu', 'stu', 'oth', 'edu', 'eng', 'edu', 'stu', 'pro', 'law', 'art', 'adm', 'hea', 'oth', 'edu', 'oth', 'oth', 'oth', 'hea', 'edu', 'mar', 'oth', 'adm', 'sci', 'sci', 'pro', 'oth', 'ent', 'adm', 'exe', 'pro', 'sci', 'lib', 'lib', 'exe', 'edu', 'stu', 'art', 'adm', 'adm', 'edu', 'stu', 'adm', 'sci', 'wri', 'tec', 'stu', 'wri', 'pro', 'wri', 'edu', 'stu', 'lib', 'law', 'stu', 'mar', 'eng', 'edu', 'eng', 'sal', 'edu', 'exe', 'lib', 'pro', 'eng', 'oth', 'adm', 'pro', 'lib', 'stu', 'pro', 'stu', 'edu', 'adm', 'stu', 'exe', 'stu', 'lib', 'stu', 'lib', 'sci', 'eng', 'ret', 'edu', 'wri', 'adm', 'adm', 'art', 'edu', 'stu', 'edu', 'edu', 'tec', 'stu', 'stu', 'eng', 'stu', 'stu', 'exe', 'doc', 'eng', 'lib', 'edu', 'ent', 'non', 'stu', 'stu', 'stu', 'art', 'adm', 'stu', 'pro', 'wri', 'exe', 'adm', 'eng', 'eng', 'lib', 'stu', 'eng', 'sci', 'oth', 'stu', 'eng', 'stu', 'adm', 'lib', 'pro', 'lib', 'stu', 'adm', 'pro', 'exe', 'pro', 'stu', 'sal', 'mar', 'non', 'eng', 'stu', 'pro', 'wri', 'tec', 'edu', 'adm', 'edu', 'exe', 'doc', 'pro', 'stu', 'edu', 'stu', 'stu', 'pro', 'oth', 'stu', 'ret', 'sci', 'edu', 'tec', 'oth', 'mar', 'stu', 'edu', 'oth', 'adm', 'ret', 'pro', 'stu', 'edu', 'stu', 'stu', 'stu', 'tec', 'adm', 'stu', 'adm', 'edu', 'edu', 'ent', 'stu', 'oth', 'lib', 'exe', 'sal', 'sci', 'lib', 'law', 'eng', 'stu', 'oth', 'eng', 'lib', 'lib', 'oth', 'stu', 'stu', 'ret', 'stu', 'edu', 'pro', 'sci', 'lib', 'stu', 'hom', 'exe', 'edu', 'stu', 'oth', 'stu', 'hom', 'stu', 'eng', 'law', 'stu', 'stu', 'stu', 'stu', 'wri', 'eng', 'stu', 'oth', 'exe', 'ent', 'oth', 'stu', 'stu', 'pro', 'eng', 'art', 'eng', 'adm', 'pro', 'wri', 'sal', 'ent', 'oth', 'wri', 'wri', 'stu', 'wri', 'stu', 'adm', 'oth', 'eng', 'stu', 'oth', 'oth', 'adm', 'hea', 'eng', 'oth', 'pro', 'hea', 'edu', 'eng', 'stu', 'adm', 'art', 'edu', 'edu', 'edu', 'pro', 'edu', 'stu', 'oth', 'non', 'law', 'edu', 'pro', 'ent', 'oth', 'mar', 'stu', 'edu', 'doc', 'stu', 'stu', 'sci', 'mar', 'ent', 'art', 'stu', 'eng', 'adm', 'oth', 'adm', 'adm', 'oth', 'tec', 'stu', 'sal', 'law', 'wri', 'edu', 'adm', 'ent', 'lib', 'edu', 'stu', 'adm', 'stu', 'oth', 'adm', 'tec', 'sal', 'tec', 'stu', 'oth', 'stu', 'stu', 'hea', 'wri', 'oth', 'stu', 'eng', 'eng', 'edu', 'pro', 'stu', 'stu', 'stu', 'exe', 'pro', 'stu', 'stu', 'oth', 'edu', 'ret', 'ret', 'stu', 'sci', 'stu', 'edu', 'edu', 'eng', 'tec', 'oth', 'art', 'wri', 'edu', 'eng', 'adm', 'eng', 'stu', 'stu', 'wri', 'pro', 'adm', 'stu', 'stu', 'wri', 'wri', 'oth', 'pro', 'wri', 'mar', 'adm', 'oth', 'stu', 'oth', 'adm', 'pro', 'mar', 'lib', 'stu', 'wri', 'oth', 'hea', 'stu', 'eng', 'adm', 'edu', 'adm', 'mar', 'lib', 'stu', 'adm', 'eng', 'sal', 'stu', 'lib', 'stu', 'edu', 'eng', 'eng', 'sci', 'adm', 'eng', 'stu', 'stu', 'sci', 'oth', 'tec', 'exe', 'edu', 'wri', 'sci', 'stu', 'pro', 'oth', 'edu', 'sci', 'edu', 'edu', 'wri', 'wri', 'exe', 'stu', 'eng', 'adm', 'lib', 'ret', 'stu', 'stu', 'ent', 'edu', 'edu', 'edu', 'art', 'edu', 'ret', 'edu', 'mar', 'exe', 'stu', 'adm', 'edu', 'stu', 'oth', 'stu', 'eng', 'stu', 'lib', 'stu', 'oth', 'stu', 'law', 'edu', 'lib', 'stu', 'edu', 'edu', 'pro', 'art', 'oth', 'mar', 'stu', 'pro', 'art', 'oth', 'pro', 'edu', 'eng', 'pro', 'hea', 'oth', 'stu', 'stu', 'lib', 'edu', 'mar', 'edu', 'edu', 'sci', 'wri', 'stu', 'stu', 'wri', 'stu', 'pro', 'edu', 'stu', 'pro', 'sci', 'eng', 'non', 'oth', 'hea', 'stu', 'stu', 'pro', 'eng', 'oth', 'edu', 'oth', 'eng', 'lib', 'stu', 'stu', 'stu', 'sci', 'ret', 'pro', 'stu', 'edu', 'eng', 'stu', 'eng', 'ret', 'oth', 'exe', 'stu', 'hea', 'edu', 'non', 'pro', 'edu', 'stu', 'pro', 'lib', 'oth', 'eng', 'adm', 'adm', 'lib', 'wri', 'oth', 'tec', 'pro', 'adm', 'edu', 'stu', 'oth', 'pro', 'oth', 'edu', 'stu', 'law', 'mar', 'pro', 'lib', 'stu', 'lib', 'edu', 'hea', 'adm', 'oth', 'sal', 'edu', 'eng', 'hea', 'pro', 'wri', 'oth', 'oth', 'pro', 'oth', 'stu', 'lib', 'oth', 'edu', 'lib', 'stu', 'stu', 'lib', 'hom', 'oth', 'stu', 'stu', 'stu', 'oth', 'eng', 'tec', 'adm', 'tec', 'tec', 'oth', 'adm', 'ent', 'hom', 'exe', 'exe', 'stu', 'adm', 'stu', 'exe', 'stu', 'sci', 'edu', 'oth', 'oth', 'oth', 'hea', 'wri', 'pro', 'tec', 'tec', 'edu', 'wri', 'stu', 'pro', 'mar', 'wri', 'eng', 'oth', 'adm', 'oth', 'adm', 'oth', 'ret', 'sal', 'lib', 'edu', 'non', 'stu', 'stu', 'stu', 'oth', 'stu', 'adm', 'sci', 'edu', 'stu', 'oth', 'eng', 'adm', 'exe', 'stu', 'stu', 'wri', 'stu', 'stu', 'exe', 'lib', 'pro', 'stu', 'stu', 'pro', 'stu', 'art', 'mar', 'adm', 'eng', 'eng', 'stu', 'adm', 'oth', 'tec', 'edu', 'pro', 'stu', 'edu', 'pro', 'wri', 'oth', 'wri', 'adm', 'pro', 'wri', 'adm', 'adm', 'edu', 'oth', 'mar', 'hea', 'sal', 'mar', 'oth', 'edu', 'tec', 'stu', 'oth', 'oth', 'oth', 'stu', 'lib', 'adm', 'stu', 'eng', 'lib', 'art', 'oth', 'eng', 'art', 'eng', 'lib', 'wri', 'pro', 'oth', 'tec', 'wri', 'oth', 'exe', 'art', 'art', 'stu', 'ent', 'art', 'doc', 'wri', 'lib', 'eng', 'doc', 'law', 'stu', 'eng', 'stu', 'tec', 'oth', 'adm', 'wri', 'stu', 'lib', 'mar', 'adm', 'edu', 'oth', 'ret', 'stu', 'exe', 'stu', 'pro', 'art', 'oth', 'sci', 'pro', 'stu', 'stu', 'exe', 'stu', 'adm', 'sci', 'stu', 'oth', 'oth', 'edu', 'adm', 'stu', 'mar', 'eng', 'lib', 'eng', 'oth', 'stu', 'stu', 'sci', 'tec', 'stu', 'adm', 'oth', 'stu', 'edu', 'lib', 'wri', 'oth', 'hom', 'oth', 'ret', 'exe', 'art', 'edu', 'stu', 'oth', 'lib', 'oth', 'lib', 'edu', 'hea', 'wri', 'oth', 'stu', 'oth', 'ent', 'eng', 'stu', 'sci', 'oth', 'art', 'stu', 'adm', 'stu', 'oth', 'sal', 'ent', 'pro', 'stu', 'sci', 'sci', 'edu', 'edu', 'stu', 'eng', 'doc', 'oth', 'edu', 'tec', 'stu', 'adm', 'stu', 'lib', 'stu']\n"
     ]
    }
   ],
   "source": [
    "#Figure 7 Figure 8\n",
    "\n",
    "#Segmentation and interpretation of clusters with sklearn\n",
    "\n",
    "##############################################\n",
    "# Format metadata for users\n",
    "##############################################\n",
    "\n",
    "dfUser = pandas.read_csv(dfDirectory + \"u.user\", sep=\"\\t\")\n",
    "\n",
    "#Create list with ages of users\n",
    "ages=[24]\n",
    "\n",
    "for i in range(0,8):\n",
    "    ages.append(int(dfUser.iloc[i][0][2] + dfUser.iloc[i][0][3]))\n",
    "\n",
    "for i in range(8,28):\n",
    "    ages.append(int(dfUser.iloc[i][0][3] + dfUser.iloc[i][0][4]))\n",
    "\n",
    "ages.append(7)\n",
    "\n",
    "for i in range(29,98):\n",
    "    ages.append(int(dfUser.iloc[i][0][3] + dfUser.iloc[i][0][4]))\n",
    "\n",
    "for i in range(98,942):\n",
    "    ages.append(int(dfUser.iloc[i][0][4] + dfUser.iloc[i][0][5]))\n",
    "\n",
    "print(\"Get ages of users\")\n",
    "print(ages)\n",
    "\n",
    "#Create list with gender of users\n",
    "gender = [0]\n",
    "\n",
    "for i in range(0,8):\n",
    "    if dfUser.iloc[i][0][5] == 'M':\n",
    "        gender.append(0)\n",
    "    else:\n",
    "        gender.append(1)\n",
    "\n",
    "for i in range(8,28):\n",
    "    if dfUser.iloc[i][0][6] == 'M':\n",
    "        gender.append(0)\n",
    "    else:\n",
    "        gender.append(1)\n",
    "\n",
    "gender.append(0)\n",
    "\n",
    "for i in range(29,98):\n",
    "    if dfUser.iloc[i][0][6] == 'M':\n",
    "        gender.append(0)\n",
    "    else:\n",
    "        gender.append(1)\n",
    "\n",
    "for i in range(98,942):\n",
    "    if dfUser.iloc[i][0][7] == 'M':\n",
    "        gender.append(0)\n",
    "    else:\n",
    "        gender.append(1)\n",
    "\n",
    "print(\"Get genders of users\")\n",
    "print(gender)\n",
    "\n",
    "#Create list with jobs of users\n",
    "jobs = ['tec']\n",
    "\n",
    "for i in range(0,8):\n",
    "    jobs.append(dfUser.iloc[i][0][7] + dfUser.iloc[i][0][8] + dfUser.iloc[i][0][9])\n",
    "\n",
    "for i in range(8,28):\n",
    "    jobs.append(dfUser.iloc[i][0][8] + dfUser.iloc[i][0][9] + dfUser.iloc[i][0][10])\n",
    "\n",
    "jobs.append('stu')\n",
    "\n",
    "for i in range(29,98):\n",
    "    jobs.append(dfUser.iloc[i][0][8] + dfUser.iloc[i][0][9] + dfUser.iloc[i][0][10])\n",
    "\n",
    "for i in range(98,942):\n",
    "    jobs.append(dfUser.iloc[i][0][9] + dfUser.iloc[i][0][10] + dfUser.iloc[i][0][11])\n",
    "\n",
    "print(\"Get jobs of users\")\n",
    "print(jobs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import statistics\n",
    "\n",
    "###############################################\n",
    "# Interpretation of segmentation of users\n",
    "###############################################\n",
    "\n",
    "#Get caracteristics of each cluster\n",
    "def caractCluster(i,dic):\n",
    "    #i : cluster index\n",
    "    #dic : dictionary {i : elements of cluster i}\n",
    "    #Warning: here i corresponds to i+1 in database\n",
    "    avg_age = 0\n",
    "    median_age = 0\n",
    "    var_age = 0\n",
    "    rate_women = 0\n",
    "    dic_occ = {'adm':0, 'art':0, 'doc':0, 'edu':0, 'eng':0, 'ent':0, 'exe':0, 'hea':0, 'hom':0, 'law':0,\n",
    "    'lib':0, 'mar':0, 'non':0, 'oth':0, 'pro':0, 'ret':0, 'sal':0, 'sci':0, 'stu':0, 'tec':0, 'wri':0}\n",
    "    ages_cluster = []\n",
    "    occ_cluster = []\n",
    "    gender_cluster = []\n",
    "    for k in dic[i]:\n",
    "        ages_cluster.append(ages[k])\n",
    "        occ_cluster.append(jobs[k])\n",
    "        gender_cluster.append(gender[k])\n",
    "    avg_age = statistics.mean(ages_cluster)\n",
    "    median_age = statistics.median(ages_cluster)\n",
    "    if len(ages_cluster) != 1:\n",
    "        var_age = statistics.variance(ages_cluster)\n",
    "    rate_women = sum(gender_cluster)/float(len(gender_cluster))\n",
    "    for k in occ_cluster:\n",
    "        dic_occ[k] += 1\n",
    "    dic_occ['adm'] = dic_occ['adm']/79\n",
    "    dic_occ['art'] = dic_occ['art']/28\n",
    "    dic_occ['doc'] = dic_occ['doc']/7\n",
    "    dic_occ['edu'] = dic_occ['edu']/95\n",
    "    dic_occ['eng'] = dic_occ['eng']/67\n",
    "    dic_occ['ent'] = dic_occ['ent']/18\n",
    "    dic_occ['exe'] = dic_occ['exe']/32\n",
    "    dic_occ['hea'] = dic_occ['hea']/16\n",
    "    dic_occ['hom'] = dic_occ['hom']/7\n",
    "    dic_occ['law'] = dic_occ['law']/12\n",
    "    dic_occ['lib'] = dic_occ['lib']/51\n",
    "    dic_occ['mar'] = dic_occ['mar']/56\n",
    "    dic_occ['non'] = dic_occ['non']/9\n",
    "    dic_occ['oth'] = dic_occ['oth']/105\n",
    "    dic_occ['pro'] = dic_occ['pro']/66\n",
    "    dic_occ['ret'] = dic_occ['ret']/14\n",
    "    dic_occ['sal'] = dic_occ['sal']/12\n",
    "    dic_occ['sci'] = dic_occ['sci']/31\n",
    "    dic_occ['stu'] = dic_occ['stu']/196\n",
    "    dic_occ['tec'] = dic_occ['tec']/27\n",
    "    dic_occ['wri'] = dic_occ['wri']/45\n",
    "    return (dic_occ,max(dic_occ, key=dic_occ.get))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster number\n",
      "0\n",
      "caracteristics of cluster\n",
      "({'oth': 0.01904761904761905, 'edu': 0.021052631578947368, 'eng': 0.0, 'hea': 0.0625, 'sal': 0.0, 'hom': 0.0, 'tec': 0.0, 'exe': 0.03125, 'non': 0.0, 'mar': 0.017857142857142856, 'ret': 0.0, 'adm': 0.0, 'art': 0.0, 'stu': 0.00510204081632653, 'lib': 0.0196078431372549, 'doc': 0.0, 'sci': 0.0, 'wri': 0.1111111111111111, 'law': 0.0, 'ent': 0.05555555555555555, 'pro': 0.045454545454545456}, 'wri')\n",
      "cluster number\n",
      "1\n",
      "caracteristics of cluster\n",
      "({'oth': 0.009523809523809525, 'edu': 0.010526315789473684, 'eng': 0.014925373134328358, 'hea': 0.0, 'sal': 0.0, 'hom': 0.0, 'tec': 0.0, 'exe': 0.0, 'non': 0.0, 'mar': 0.0, 'ret': 0.0, 'adm': 0.012658227848101266, 'art': 0.0, 'stu': 0.00510204081632653, 'lib': 0.0392156862745098, 'doc': 0.0, 'sci': 0.06451612903225806, 'wri': 0.022222222222222223, 'law': 0.0, 'ent': 0.0, 'pro': 0.015151515151515152}, 'sci')\n",
      "cluster number\n",
      "2\n",
      "caracteristics of cluster\n",
      "({'oth': 0.08571428571428572, 'edu': 0.07368421052631578, 'eng': 0.05970149253731343, 'hea': 0.0625, 'sal': 0.08333333333333333, 'hom': 0.0, 'tec': 0.037037037037037035, 'exe': 0.0625, 'non': 0.0, 'mar': 0.017857142857142856, 'ret': 0.07142857142857142, 'adm': 0.06329113924050633, 'art': 0.10714285714285714, 'stu': 0.061224489795918366, 'lib': 0.058823529411764705, 'doc': 0.0, 'sci': 0.0967741935483871, 'wri': 0.06666666666666667, 'law': 0.08333333333333333, 'ent': 0.05555555555555555, 'pro': 0.030303030303030304}, 'art')\n",
      "cluster number\n",
      "3\n",
      "caracteristics of cluster\n",
      "({'oth': 0.009523809523809525, 'edu': 0.010526315789473684, 'eng': 0.0, 'hea': 0.0, 'sal': 0.0, 'hom': 0.0, 'tec': 0.0, 'exe': 0.0625, 'non': 0.0, 'mar': 0.0, 'ret': 0.0, 'adm': 0.0, 'art': 0.0, 'stu': 0.0, 'lib': 0.0, 'doc': 0.0, 'sci': 0.0, 'wri': 0.0, 'law': 0.0, 'ent': 0.0, 'pro': 0.0}, 'exe')\n",
      "cluster number\n",
      "4\n",
      "caracteristics of cluster\n",
      "({'oth': 0.01904761904761905, 'edu': 0.031578947368421054, 'eng': 0.014925373134328358, 'hea': 0.0, 'sal': 0.0, 'hom': 0.0, 'tec': 0.037037037037037035, 'exe': 0.03125, 'non': 0.1111111111111111, 'mar': 0.0, 'ret': 0.0, 'adm': 0.0379746835443038, 'art': 0.0, 'stu': 0.025510204081632654, 'lib': 0.0, 'doc': 0.0, 'sci': 0.0, 'wri': 0.0, 'law': 0.0, 'ent': 0.05555555555555555, 'pro': 0.030303030303030304}, 'non')\n",
      "cluster number\n",
      "5\n",
      "caracteristics of cluster\n",
      "({'oth': 0.01904761904761905, 'edu': 0.010526315789473684, 'eng': 0.014925373134328358, 'hea': 0.0, 'sal': 0.0, 'hom': 0.0, 'tec': 0.037037037037037035, 'exe': 0.0, 'non': 0.0, 'mar': 0.0, 'ret': 0.0, 'adm': 0.012658227848101266, 'art': 0.0, 'stu': 0.015306122448979591, 'lib': 0.0196078431372549, 'doc': 0.0, 'sci': 0.03225806451612903, 'wri': 0.022222222222222223, 'law': 0.0, 'ent': 0.0, 'pro': 0.015151515151515152}, 'tec')\n",
      "cluster number\n",
      "6\n",
      "caracteristics of cluster\n",
      "({'oth': 0.0, 'edu': 0.0, 'eng': 0.0, 'hea': 0.0, 'sal': 0.0, 'hom': 0.0, 'tec': 0.037037037037037035, 'exe': 0.0, 'non': 0.0, 'mar': 0.0, 'ret': 0.0, 'adm': 0.0, 'art': 0.0, 'stu': 0.015306122448979591, 'lib': 0.0, 'doc': 0.0, 'sci': 0.03225806451612903, 'wri': 0.022222222222222223, 'law': 0.0, 'ent': 0.0, 'pro': 0.0}, 'tec')\n",
      "cluster number\n",
      "7\n",
      "caracteristics of cluster\n",
      "({'oth': 0.009523809523809525, 'edu': 0.0, 'eng': 0.04477611940298507, 'hea': 0.0, 'sal': 0.0, 'hom': 0.0, 'tec': 0.037037037037037035, 'exe': 0.0, 'non': 0.0, 'mar': 0.0, 'ret': 0.0, 'adm': 0.0, 'art': 0.0, 'stu': 0.030612244897959183, 'lib': 0.0, 'doc': 0.0, 'sci': 0.0, 'wri': 0.0, 'law': 0.0, 'ent': 0.05555555555555555, 'pro': 0.015151515151515152}, 'ent')\n",
      "cluster number\n",
      "8\n",
      "caracteristics of cluster\n",
      "({'oth': 0.0, 'edu': 0.0, 'eng': 0.0, 'hea': 0.0, 'sal': 0.0, 'hom': 0.0, 'tec': 0.0, 'exe': 0.0, 'non': 0.0, 'mar': 0.0, 'ret': 0.0, 'adm': 0.0, 'art': 0.0, 'stu': 0.01020408163265306, 'lib': 0.0, 'doc': 0.0, 'sci': 0.0, 'wri': 0.022222222222222223, 'law': 0.0, 'ent': 0.0, 'pro': 0.0}, 'wri')\n",
      "cluster number\n",
      "9\n",
      "caracteristics of cluster\n",
      "({'oth': 0.009523809523809525, 'edu': 0.0, 'eng': 0.014925373134328358, 'hea': 0.0, 'sal': 0.0, 'hom': 0.14285714285714285, 'tec': 0.037037037037037035, 'exe': 0.0625, 'non': 0.0, 'mar': 0.0, 'ret': 0.0, 'adm': 0.012658227848101266, 'art': 0.0, 'stu': 0.030612244897959183, 'lib': 0.0, 'doc': 0.14285714285714285, 'sci': 0.0, 'wri': 0.022222222222222223, 'law': 0.0, 'ent': 0.0, 'pro': 0.030303030303030304}, 'hom')\n",
      "cluster number\n",
      "10\n",
      "caracteristics of cluster\n",
      "({'oth': 0.0, 'edu': 0.0, 'eng': 0.014925373134328358, 'hea': 0.0625, 'sal': 0.0, 'hom': 0.0, 'tec': 0.0, 'exe': 0.0, 'non': 0.0, 'mar': 0.0, 'ret': 0.0, 'adm': 0.0, 'art': 0.0, 'stu': 0.0, 'lib': 0.0, 'doc': 0.0, 'sci': 0.0, 'wri': 0.0, 'law': 0.0, 'ent': 0.0, 'pro': 0.0}, 'hea')\n",
      "cluster number\n",
      "11\n",
      "caracteristics of cluster\n",
      "({'oth': 0.009523809523809525, 'edu': 0.021052631578947368, 'eng': 0.0, 'hea': 0.0, 'sal': 0.0, 'hom': 0.0, 'tec': 0.0, 'exe': 0.0, 'non': 0.0, 'mar': 0.0, 'ret': 0.0, 'adm': 0.0, 'art': 0.0, 'stu': 0.0, 'lib': 0.0, 'doc': 0.0, 'sci': 0.0, 'wri': 0.0, 'law': 0.0, 'ent': 0.05555555555555555, 'pro': 0.0}, 'ent')\n",
      "cluster number\n",
      "12\n",
      "caracteristics of cluster\n",
      "({'oth': 0.01904761904761905, 'edu': 0.010526315789473684, 'eng': 0.0, 'hea': 0.0625, 'sal': 0.0, 'hom': 0.0, 'tec': 0.0, 'exe': 0.0, 'non': 0.0, 'mar': 0.0, 'ret': 0.0, 'adm': 0.0, 'art': 0.0, 'stu': 0.0, 'lib': 0.0, 'doc': 0.0, 'sci': 0.0, 'wri': 0.0, 'law': 0.0, 'ent': 0.0, 'pro': 0.0}, 'hea')\n",
      "cluster number\n",
      "13\n",
      "caracteristics of cluster\n",
      "({'oth': 0.0, 'edu': 0.0, 'eng': 0.0, 'hea': 0.0, 'sal': 0.0, 'hom': 0.0, 'tec': 0.0, 'exe': 0.0, 'non': 0.0, 'mar': 0.0, 'ret': 0.0, 'adm': 0.0, 'art': 0.0, 'stu': 0.0, 'lib': 0.0, 'doc': 0.0, 'sci': 0.0, 'wri': 0.022222222222222223, 'law': 0.0, 'ent': 0.0, 'pro': 0.0}, 'wri')\n",
      "cluster number\n",
      "14\n",
      "caracteristics of cluster\n",
      "({'oth': 0.0761904761904762, 'edu': 0.06315789473684211, 'eng': 0.05970149253731343, 'hea': 0.125, 'sal': 0.0, 'hom': 0.2857142857142857, 'tec': 0.07407407407407407, 'exe': 0.03125, 'non': 0.1111111111111111, 'mar': 0.07142857142857142, 'ret': 0.0, 'adm': 0.10126582278481013, 'art': 0.07142857142857142, 'stu': 0.07653061224489796, 'lib': 0.13725490196078433, 'doc': 0.0, 'sci': 0.0967741935483871, 'wri': 0.022222222222222223, 'law': 0.16666666666666666, 'ent': 0.16666666666666666, 'pro': 0.09090909090909091}, 'hom')\n",
      "cluster number\n",
      "15\n",
      "caracteristics of cluster\n",
      "({'oth': 0.02857142857142857, 'edu': 0.0, 'eng': 0.0, 'hea': 0.0625, 'sal': 0.0, 'hom': 0.0, 'tec': 0.0, 'exe': 0.03125, 'non': 0.0, 'mar': 0.017857142857142856, 'ret': 0.07142857142857142, 'adm': 0.012658227848101266, 'art': 0.0, 'stu': 0.00510204081632653, 'lib': 0.0196078431372549, 'doc': 0.0, 'sci': 0.0, 'wri': 0.022222222222222223, 'law': 0.0, 'ent': 0.0, 'pro': 0.045454545454545456}, 'ret')\n",
      "cluster number\n",
      "16\n",
      "caracteristics of cluster\n",
      "({'oth': 0.009523809523809525, 'edu': 0.010526315789473684, 'eng': 0.014925373134328358, 'hea': 0.0, 'sal': 0.0, 'hom': 0.0, 'tec': 0.0, 'exe': 0.0, 'non': 0.0, 'mar': 0.017857142857142856, 'ret': 0.0, 'adm': 0.012658227848101266, 'art': 0.0, 'stu': 0.0, 'lib': 0.0, 'doc': 0.0, 'sci': 0.0, 'wri': 0.022222222222222223, 'law': 0.0, 'ent': 0.0, 'pro': 0.015151515151515152}, 'wri')\n",
      "cluster number\n",
      "17\n",
      "caracteristics of cluster\n",
      "({'oth': 0.02857142857142857, 'edu': 0.021052631578947368, 'eng': 0.029850746268656716, 'hea': 0.0, 'sal': 0.0, 'hom': 0.0, 'tec': 0.037037037037037035, 'exe': 0.0, 'non': 0.0, 'mar': 0.0, 'ret': 0.0, 'adm': 0.012658227848101266, 'art': 0.0, 'stu': 0.015306122448979591, 'lib': 0.0, 'doc': 0.0, 'sci': 0.03225806451612903, 'wri': 0.0, 'law': 0.0, 'ent': 0.0, 'pro': 0.015151515151515152}, 'tec')\n",
      "cluster number\n",
      "18\n",
      "caracteristics of cluster\n",
      "({'oth': 0.009523809523809525, 'edu': 0.0, 'eng': 0.0, 'hea': 0.0625, 'sal': 0.0, 'hom': 0.0, 'tec': 0.0, 'exe': 0.0, 'non': 0.0, 'mar': 0.0, 'ret': 0.0, 'adm': 0.0, 'art': 0.0, 'stu': 0.00510204081632653, 'lib': 0.0196078431372549, 'doc': 0.0, 'sci': 0.0, 'wri': 0.022222222222222223, 'law': 0.0, 'ent': 0.0, 'pro': 0.0}, 'hea')\n",
      "cluster number\n",
      "19\n",
      "caracteristics of cluster\n",
      "({'oth': 0.0, 'edu': 0.021052631578947368, 'eng': 0.0, 'hea': 0.0, 'sal': 0.08333333333333333, 'hom': 0.0, 'tec': 0.0, 'exe': 0.0, 'non': 0.0, 'mar': 0.0, 'ret': 0.0, 'adm': 0.0, 'art': 0.03571428571428571, 'stu': 0.025510204081632654, 'lib': 0.0196078431372549, 'doc': 0.0, 'sci': 0.06451612903225806, 'wri': 0.0, 'law': 0.0, 'ent': 0.0, 'pro': 0.030303030303030304}, 'sal')\n",
      "cluster number\n",
      "20\n",
      "caracteristics of cluster\n",
      "({'oth': 0.0, 'edu': 0.042105263157894736, 'eng': 0.014925373134328358, 'hea': 0.0, 'sal': 0.0, 'hom': 0.0, 'tec': 0.0, 'exe': 0.0, 'non': 0.0, 'mar': 0.0, 'ret': 0.07142857142857142, 'adm': 0.0, 'art': 0.0, 'stu': 0.00510204081632653, 'lib': 0.0, 'doc': 0.0, 'sci': 0.0, 'wri': 0.022222222222222223, 'law': 0.0, 'ent': 0.0, 'pro': 0.0}, 'ret')\n",
      "cluster number\n",
      "21\n",
      "caracteristics of cluster\n",
      "({'oth': 0.009523809523809525, 'edu': 0.0, 'eng': 0.0, 'hea': 0.0, 'sal': 0.0, 'hom': 0.0, 'tec': 0.0, 'exe': 0.0, 'non': 0.0, 'mar': 0.0, 'ret': 0.0, 'adm': 0.012658227848101266, 'art': 0.0, 'stu': 0.01020408163265306, 'lib': 0.0, 'doc': 0.0, 'sci': 0.0, 'wri': 0.0, 'law': 0.0, 'ent': 0.0, 'pro': 0.015151515151515152}, 'pro')\n",
      "cluster number\n",
      "22\n",
      "caracteristics of cluster\n",
      "({'oth': 0.0, 'edu': 0.010526315789473684, 'eng': 0.0, 'hea': 0.0, 'sal': 0.0, 'hom': 0.0, 'tec': 0.037037037037037035, 'exe': 0.0, 'non': 0.0, 'mar': 0.0, 'ret': 0.0, 'adm': 0.0, 'art': 0.0, 'stu': 0.00510204081632653, 'lib': 0.0, 'doc': 0.0, 'sci': 0.0, 'wri': 0.0, 'law': 0.0, 'ent': 0.0, 'pro': 0.0}, 'tec')\n",
      "cluster number\n",
      "23\n",
      "caracteristics of cluster\n",
      "({'oth': 0.0, 'edu': 0.0, 'eng': 0.0, 'hea': 0.0, 'sal': 0.0, 'hom': 0.0, 'tec': 0.0, 'exe': 0.0, 'non': 0.0, 'mar': 0.0, 'ret': 0.0, 'adm': 0.0, 'art': 0.0, 'stu': 0.00510204081632653, 'lib': 0.0, 'doc': 0.0, 'sci': 0.0, 'wri': 0.0, 'law': 0.0, 'ent': 0.0, 'pro': 0.015151515151515152}, 'pro')\n",
      "cluster number\n",
      "24\n",
      "caracteristics of cluster\n",
      "({'oth': 0.0, 'edu': 0.0, 'eng': 0.029850746268656716, 'hea': 0.0, 'sal': 0.0, 'hom': 0.0, 'tec': 0.0, 'exe': 0.0, 'non': 0.0, 'mar': 0.017857142857142856, 'ret': 0.0, 'adm': 0.012658227848101266, 'art': 0.0, 'stu': 0.01020408163265306, 'lib': 0.0, 'doc': 0.0, 'sci': 0.03225806451612903, 'wri': 0.0, 'law': 0.0, 'ent': 0.05555555555555555, 'pro': 0.0}, 'ent')\n",
      "cluster number\n",
      "25\n",
      "caracteristics of cluster\n",
      "({'oth': 0.01904761904761905, 'edu': 0.0, 'eng': 0.014925373134328358, 'hea': 0.0, 'sal': 0.0, 'hom': 0.0, 'tec': 0.0, 'exe': 0.0, 'non': 0.0, 'mar': 0.0, 'ret': 0.0, 'adm': 0.0, 'art': 0.0, 'stu': 0.0, 'lib': 0.0, 'doc': 0.0, 'sci': 0.0, 'wri': 0.0, 'law': 0.0, 'ent': 0.0, 'pro': 0.0}, 'oth')\n",
      "cluster number\n",
      "26\n",
      "caracteristics of cluster\n",
      "({'oth': 0.0, 'edu': 0.0, 'eng': 0.0, 'hea': 0.0, 'sal': 0.0, 'hom': 0.0, 'tec': 0.0, 'exe': 0.0, 'non': 0.0, 'mar': 0.0, 'ret': 0.0, 'adm': 0.0, 'art': 0.0, 'stu': 0.01020408163265306, 'lib': 0.0, 'doc': 0.0, 'sci': 0.0, 'wri': 0.0, 'law': 0.0, 'ent': 0.0, 'pro': 0.0}, 'stu')\n",
      "cluster number\n",
      "27\n",
      "caracteristics of cluster\n",
      "({'oth': 0.009523809523809525, 'edu': 0.0, 'eng': 0.0, 'hea': 0.0, 'sal': 0.0, 'hom': 0.0, 'tec': 0.0, 'exe': 0.0, 'non': 0.0, 'mar': 0.0, 'ret': 0.0, 'adm': 0.0, 'art': 0.0, 'stu': 0.0, 'lib': 0.058823529411764705, 'doc': 0.14285714285714285, 'sci': 0.03225806451612903, 'wri': 0.0, 'law': 0.0, 'ent': 0.0, 'pro': 0.0}, 'doc')\n",
      "cluster number\n",
      "28\n",
      "caracteristics of cluster\n",
      "({'oth': 0.01904761904761905, 'edu': 0.05263157894736842, 'eng': 0.014925373134328358, 'hea': 0.0625, 'sal': 0.0, 'hom': 0.0, 'tec': 0.0, 'exe': 0.03125, 'non': 0.0, 'mar': 0.0, 'ret': 0.0, 'adm': 0.02531645569620253, 'art': 0.03571428571428571, 'stu': 0.015306122448979591, 'lib': 0.0, 'doc': 0.0, 'sci': 0.03225806451612903, 'wri': 0.0, 'law': 0.16666666666666666, 'ent': 0.05555555555555555, 'pro': 0.015151515151515152}, 'law')\n",
      "cluster number\n",
      "29\n",
      "caracteristics of cluster\n",
      "({'oth': 0.0, 'edu': 0.0, 'eng': 0.0, 'hea': 0.0, 'sal': 0.08333333333333333, 'hom': 0.0, 'tec': 0.0, 'exe': 0.0, 'non': 0.0, 'mar': 0.0, 'ret': 0.0, 'adm': 0.0, 'art': 0.0, 'stu': 0.00510204081632653, 'lib': 0.0, 'doc': 0.0, 'sci': 0.0, 'wri': 0.0, 'law': 0.0, 'ent': 0.0, 'pro': 0.015151515151515152}, 'sal')\n",
      "cluster number\n",
      "30\n",
      "caracteristics of cluster\n",
      "({'oth': 0.0, 'edu': 0.021052631578947368, 'eng': 0.0, 'hea': 0.0, 'sal': 0.0, 'hom': 0.0, 'tec': 0.0, 'exe': 0.0625, 'non': 0.0, 'mar': 0.017857142857142856, 'ret': 0.07142857142857142, 'adm': 0.02531645569620253, 'art': 0.0, 'stu': 0.015306122448979591, 'lib': 0.0392156862745098, 'doc': 0.14285714285714285, 'sci': 0.03225806451612903, 'wri': 0.022222222222222223, 'law': 0.08333333333333333, 'ent': 0.0, 'pro': 0.0}, 'doc')\n",
      "cluster number\n",
      "31\n",
      "caracteristics of cluster\n",
      "({'oth': 0.0, 'edu': 0.0, 'eng': 0.0, 'hea': 0.0, 'sal': 0.0, 'hom': 0.0, 'tec': 0.0, 'exe': 0.0, 'non': 0.0, 'mar': 0.0, 'ret': 0.0, 'adm': 0.0, 'art': 0.0, 'stu': 0.00510204081632653, 'lib': 0.0, 'doc': 0.0, 'sci': 0.0, 'wri': 0.0, 'law': 0.0, 'ent': 0.0, 'pro': 0.0}, 'stu')\n",
      "cluster number\n",
      "32\n",
      "caracteristics of cluster\n",
      "({'oth': 0.01904761904761905, 'edu': 0.031578947368421054, 'eng': 0.0, 'hea': 0.0625, 'sal': 0.0, 'hom': 0.0, 'tec': 0.037037037037037035, 'exe': 0.0, 'non': 0.0, 'mar': 0.017857142857142856, 'ret': 0.07142857142857142, 'adm': 0.02531645569620253, 'art': 0.0, 'stu': 0.01020408163265306, 'lib': 0.0196078431372549, 'doc': 0.0, 'sci': 0.0, 'wri': 0.0, 'law': 0.0, 'ent': 0.0, 'pro': 0.0}, 'ret')\n",
      "cluster number\n",
      "33\n",
      "caracteristics of cluster\n",
      "({'oth': 0.0, 'edu': 0.0, 'eng': 0.0, 'hea': 0.0, 'sal': 0.0, 'hom': 0.0, 'tec': 0.0, 'exe': 0.0, 'non': 0.0, 'mar': 0.0, 'ret': 0.0, 'adm': 0.0, 'art': 0.0, 'stu': 0.0, 'lib': 0.0196078431372549, 'doc': 0.0, 'sci': 0.0, 'wri': 0.0, 'law': 0.0, 'ent': 0.0, 'pro': 0.0}, 'lib')\n",
      "cluster number\n",
      "34\n",
      "caracteristics of cluster\n",
      "({'oth': 0.009523809523809525, 'edu': 0.010526315789473684, 'eng': 0.0, 'hea': 0.0, 'sal': 0.08333333333333333, 'hom': 0.0, 'tec': 0.0, 'exe': 0.03125, 'non': 0.0, 'mar': 0.0, 'ret': 0.0, 'adm': 0.02531645569620253, 'art': 0.0, 'stu': 0.025510204081632654, 'lib': 0.0196078431372549, 'doc': 0.0, 'sci': 0.0, 'wri': 0.08888888888888889, 'law': 0.0, 'ent': 0.05555555555555555, 'pro': 0.0}, 'wri')\n",
      "cluster number\n",
      "35\n",
      "caracteristics of cluster\n",
      "({'oth': 0.01904761904761905, 'edu': 0.010526315789473684, 'eng': 0.014925373134328358, 'hea': 0.0, 'sal': 0.0, 'hom': 0.0, 'tec': 0.07407407407407407, 'exe': 0.03125, 'non': 0.0, 'mar': 0.0, 'ret': 0.07142857142857142, 'adm': 0.02531645569620253, 'art': 0.03571428571428571, 'stu': 0.00510204081632653, 'lib': 0.0392156862745098, 'doc': 0.0, 'sci': 0.0, 'wri': 0.022222222222222223, 'law': 0.0, 'ent': 0.0, 'pro': 0.030303030303030304}, 'tec')\n",
      "cluster number\n",
      "36\n",
      "caracteristics of cluster\n",
      "({'oth': 0.01904761904761905, 'edu': 0.0, 'eng': 0.0, 'hea': 0.0625, 'sal': 0.0, 'hom': 0.0, 'tec': 0.0, 'exe': 0.125, 'non': 0.0, 'mar': 0.0, 'ret': 0.0, 'adm': 0.02531645569620253, 'art': 0.0, 'stu': 0.03571428571428571, 'lib': 0.0, 'doc': 0.14285714285714285, 'sci': 0.0, 'wri': 0.0, 'law': 0.0, 'ent': 0.05555555555555555, 'pro': 0.0}, 'doc')\n",
      "cluster number\n",
      "37\n",
      "caracteristics of cluster\n",
      "({'oth': 0.0, 'edu': 0.0, 'eng': 0.0, 'hea': 0.0, 'sal': 0.0, 'hom': 0.0, 'tec': 0.0, 'exe': 0.0, 'non': 0.0, 'mar': 0.0, 'ret': 0.0, 'adm': 0.02531645569620253, 'art': 0.03571428571428571, 'stu': 0.0, 'lib': 0.0196078431372549, 'doc': 0.0, 'sci': 0.0, 'wri': 0.0, 'law': 0.0, 'ent': 0.0, 'pro': 0.0}, 'art')\n",
      "cluster number\n",
      "38\n",
      "caracteristics of cluster\n",
      "({'oth': 0.0, 'edu': 0.0, 'eng': 0.0, 'hea': 0.0, 'sal': 0.0, 'hom': 0.0, 'tec': 0.0, 'exe': 0.0, 'non': 0.0, 'mar': 0.0, 'ret': 0.0, 'adm': 0.0, 'art': 0.0, 'stu': 0.0, 'lib': 0.0, 'doc': 0.0, 'sci': 0.0, 'wri': 0.0, 'law': 0.08333333333333333, 'ent': 0.0, 'pro': 0.0}, 'law')\n",
      "cluster number\n",
      "39\n",
      "caracteristics of cluster\n",
      "({'oth': 0.01904761904761905, 'edu': 0.0, 'eng': 0.0, 'hea': 0.0, 'sal': 0.0, 'hom': 0.0, 'tec': 0.0, 'exe': 0.0, 'non': 0.0, 'mar': 0.0, 'ret': 0.0, 'adm': 0.0, 'art': 0.03571428571428571, 'stu': 0.02040816326530612, 'lib': 0.0, 'doc': 0.0, 'sci': 0.0, 'wri': 0.0, 'law': 0.0, 'ent': 0.0, 'pro': 0.030303030303030304}, 'art')\n",
      "cluster number\n",
      "40\n",
      "caracteristics of cluster\n",
      "({'oth': 0.02857142857142857, 'edu': 0.021052631578947368, 'eng': 0.04477611940298507, 'hea': 0.0, 'sal': 0.16666666666666666, 'hom': 0.14285714285714285, 'tec': 0.0, 'exe': 0.03125, 'non': 0.1111111111111111, 'mar': 0.0, 'ret': 0.0, 'adm': 0.0, 'art': 0.0, 'stu': 0.05102040816326531, 'lib': 0.0784313725490196, 'doc': 0.0, 'sci': 0.03225806451612903, 'wri': 0.022222222222222223, 'law': 0.0, 'ent': 0.0, 'pro': 0.045454545454545456}, 'sal')\n",
      "cluster number\n",
      "41\n",
      "caracteristics of cluster\n",
      "({'oth': 0.009523809523809525, 'edu': 0.0, 'eng': 0.014925373134328358, 'hea': 0.0625, 'sal': 0.0, 'hom': 0.14285714285714285, 'tec': 0.037037037037037035, 'exe': 0.0, 'non': 0.0, 'mar': 0.0, 'ret': 0.0, 'adm': 0.0, 'art': 0.0, 'stu': 0.00510204081632653, 'lib': 0.0, 'doc': 0.0, 'sci': 0.0, 'wri': 0.022222222222222223, 'law': 0.0, 'ent': 0.0, 'pro': 0.0}, 'hom')\n",
      "cluster number\n",
      "42\n",
      "caracteristics of cluster\n",
      "({'oth': 0.0, 'edu': 0.0, 'eng': 0.014925373134328358, 'hea': 0.0, 'sal': 0.0, 'hom': 0.0, 'tec': 0.0, 'exe': 0.0, 'non': 0.0, 'mar': 0.0, 'ret': 0.0, 'adm': 0.02531645569620253, 'art': 0.0, 'stu': 0.0, 'lib': 0.0, 'doc': 0.0, 'sci': 0.0, 'wri': 0.0, 'law': 0.0, 'ent': 0.0, 'pro': 0.0}, 'adm')\n",
      "cluster number\n",
      "43\n",
      "caracteristics of cluster\n",
      "({'oth': 0.0, 'edu': 0.010526315789473684, 'eng': 0.04477611940298507, 'hea': 0.0, 'sal': 0.0, 'hom': 0.0, 'tec': 0.037037037037037035, 'exe': 0.03125, 'non': 0.1111111111111111, 'mar': 0.0, 'ret': 0.0, 'adm': 0.0, 'art': 0.07142857142857142, 'stu': 0.030612244897959183, 'lib': 0.0, 'doc': 0.0, 'sci': 0.0, 'wri': 0.0, 'law': 0.0, 'ent': 0.0, 'pro': 0.015151515151515152}, 'non')\n",
      "cluster number\n",
      "44\n",
      "caracteristics of cluster\n",
      "({'oth': 0.0, 'edu': 0.010526315789473684, 'eng': 0.0, 'hea': 0.0, 'sal': 0.0, 'hom': 0.0, 'tec': 0.0, 'exe': 0.0, 'non': 0.0, 'mar': 0.0, 'ret': 0.0, 'adm': 0.0, 'art': 0.0, 'stu': 0.0, 'lib': 0.0, 'doc': 0.0, 'sci': 0.0, 'wri': 0.0, 'law': 0.0, 'ent': 0.0, 'pro': 0.0}, 'edu')\n",
      "cluster number\n",
      "45\n",
      "caracteristics of cluster\n",
      "({'oth': 0.0, 'edu': 0.0, 'eng': 0.0, 'hea': 0.0, 'sal': 0.0, 'hom': 0.0, 'tec': 0.0, 'exe': 0.0, 'non': 0.0, 'mar': 0.0, 'ret': 0.0, 'adm': 0.0, 'art': 0.0, 'stu': 0.01020408163265306, 'lib': 0.0, 'doc': 0.0, 'sci': 0.0, 'wri': 0.0, 'law': 0.0, 'ent': 0.0, 'pro': 0.0}, 'stu')\n",
      "cluster number\n",
      "46\n",
      "caracteristics of cluster\n",
      "({'oth': 0.01904761904761905, 'edu': 0.021052631578947368, 'eng': 0.014925373134328358, 'hea': 0.0, 'sal': 0.0, 'hom': 0.0, 'tec': 0.0, 'exe': 0.0, 'non': 0.0, 'mar': 0.0, 'ret': 0.0, 'adm': 0.0, 'art': 0.0, 'stu': 0.015306122448979591, 'lib': 0.058823529411764705, 'doc': 0.0, 'sci': 0.0, 'wri': 0.022222222222222223, 'law': 0.0, 'ent': 0.0, 'pro': 0.0}, 'lib')\n",
      "cluster number\n",
      "47\n",
      "caracteristics of cluster\n",
      "({'oth': 0.0, 'edu': 0.0, 'eng': 0.0, 'hea': 0.0, 'sal': 0.0, 'hom': 0.0, 'tec': 0.0, 'exe': 0.0, 'non': 0.1111111111111111, 'mar': 0.0, 'ret': 0.0, 'adm': 0.0, 'art': 0.0, 'stu': 0.015306122448979591, 'lib': 0.0, 'doc': 0.0, 'sci': 0.0, 'wri': 0.0, 'law': 0.0, 'ent': 0.05555555555555555, 'pro': 0.0}, 'non')\n",
      "cluster number\n",
      "48\n",
      "caracteristics of cluster\n",
      "({'oth': 0.0, 'edu': 0.0, 'eng': 0.0, 'hea': 0.0, 'sal': 0.0, 'hom': 0.0, 'tec': 0.0, 'exe': 0.0, 'non': 0.0, 'mar': 0.0, 'ret': 0.0, 'adm': 0.0, 'art': 0.0, 'stu': 0.015306122448979591, 'lib': 0.0, 'doc': 0.0, 'sci': 0.0, 'wri': 0.022222222222222223, 'law': 0.0, 'ent': 0.0, 'pro': 0.015151515151515152}, 'wri')\n",
      "cluster number\n",
      "49\n",
      "caracteristics of cluster\n",
      "({'oth': 0.01904761904761905, 'edu': 0.0, 'eng': 0.0, 'hea': 0.0, 'sal': 0.0, 'hom': 0.0, 'tec': 0.0, 'exe': 0.0, 'non': 0.0, 'mar': 0.0, 'ret': 0.0, 'adm': 0.0, 'art': 0.03571428571428571, 'stu': 0.00510204081632653, 'lib': 0.0, 'doc': 0.0, 'sci': 0.0, 'wri': 0.0, 'law': 0.0, 'ent': 0.0, 'pro': 0.0}, 'art')\n",
      "cluster number\n",
      "50\n",
      "caracteristics of cluster\n",
      "({'oth': 0.01904761904761905, 'edu': 0.010526315789473684, 'eng': 0.014925373134328358, 'hea': 0.0, 'sal': 0.0, 'hom': 0.0, 'tec': 0.0, 'exe': 0.0, 'non': 0.0, 'mar': 0.017857142857142856, 'ret': 0.0, 'adm': 0.0, 'art': 0.0, 'stu': 0.0, 'lib': 0.0, 'doc': 0.0, 'sci': 0.0, 'wri': 0.0, 'law': 0.0, 'ent': 0.0, 'pro': 0.015151515151515152}, 'oth')\n",
      "cluster number\n",
      "51\n",
      "caracteristics of cluster\n",
      "({'oth': 0.0, 'edu': 0.010526315789473684, 'eng': 0.0, 'hea': 0.0, 'sal': 0.0, 'hom': 0.0, 'tec': 0.0, 'exe': 0.0, 'non': 0.0, 'mar': 0.0, 'ret': 0.0, 'adm': 0.0, 'art': 0.0, 'stu': 0.0, 'lib': 0.0, 'doc': 0.0, 'sci': 0.0, 'wri': 0.0, 'law': 0.0, 'ent': 0.0, 'pro': 0.0}, 'edu')\n",
      "cluster number\n",
      "52\n",
      "caracteristics of cluster\n",
      "({'oth': 0.01904761904761905, 'edu': 0.010526315789473684, 'eng': 0.014925373134328358, 'hea': 0.0, 'sal': 0.0, 'hom': 0.0, 'tec': 0.0, 'exe': 0.0, 'non': 0.0, 'mar': 0.0, 'ret': 0.0, 'adm': 0.0, 'art': 0.0, 'stu': 0.01020408163265306, 'lib': 0.0, 'doc': 0.0, 'sci': 0.03225806451612903, 'wri': 0.022222222222222223, 'law': 0.0, 'ent': 0.0, 'pro': 0.015151515151515152}, 'sci')\n",
      "cluster number\n",
      "53\n",
      "caracteristics of cluster\n",
      "({'oth': 0.0, 'edu': 0.0, 'eng': 0.014925373134328358, 'hea': 0.0, 'sal': 0.0, 'hom': 0.0, 'tec': 0.037037037037037035, 'exe': 0.0, 'non': 0.0, 'mar': 0.0, 'ret': 0.0, 'adm': 0.0, 'art': 0.0, 'stu': 0.015306122448979591, 'lib': 0.0, 'doc': 0.0, 'sci': 0.0, 'wri': 0.0, 'law': 0.0, 'ent': 0.0, 'pro': 0.015151515151515152}, 'tec')\n",
      "cluster number\n",
      "54\n",
      "caracteristics of cluster\n",
      "({'oth': 0.0, 'edu': 0.0, 'eng': 0.0, 'hea': 0.0625, 'sal': 0.0, 'hom': 0.0, 'tec': 0.0, 'exe': 0.0, 'non': 0.0, 'mar': 0.0, 'ret': 0.0, 'adm': 0.0, 'art': 0.0, 'stu': 0.0, 'lib': 0.0, 'doc': 0.0, 'sci': 0.0, 'wri': 0.0, 'law': 0.0, 'ent': 0.0, 'pro': 0.0}, 'hea')\n",
      "cluster number\n",
      "55\n",
      "caracteristics of cluster\n",
      "({'oth': 0.0, 'edu': 0.0, 'eng': 0.0, 'hea': 0.0, 'sal': 0.0, 'hom': 0.0, 'tec': 0.037037037037037035, 'exe': 0.0, 'non': 0.0, 'mar': 0.0, 'ret': 0.0, 'adm': 0.012658227848101266, 'art': 0.0, 'stu': 0.00510204081632653, 'lib': 0.0392156862745098, 'doc': 0.0, 'sci': 0.0, 'wri': 0.044444444444444446, 'law': 0.0, 'ent': 0.0, 'pro': 0.0}, 'wri')\n",
      "cluster number\n",
      "56\n",
      "caracteristics of cluster\n",
      "({'oth': 0.0, 'edu': 0.0, 'eng': 0.0, 'hea': 0.0, 'sal': 0.0, 'hom': 0.0, 'tec': 0.0, 'exe': 0.0, 'non': 0.0, 'mar': 0.0, 'ret': 0.0, 'adm': 0.0, 'art': 0.0, 'stu': 0.00510204081632653, 'lib': 0.0, 'doc': 0.0, 'sci': 0.0, 'wri': 0.0, 'law': 0.0, 'ent': 0.0, 'pro': 0.0}, 'stu')\n",
      "cluster number\n",
      "57\n",
      "caracteristics of cluster\n",
      "({'oth': 0.02857142857142857, 'edu': 0.010526315789473684, 'eng': 0.0, 'hea': 0.0, 'sal': 0.0, 'hom': 0.0, 'tec': 0.037037037037037035, 'exe': 0.0, 'non': 0.0, 'mar': 0.0, 'ret': 0.0, 'adm': 0.02531645569620253, 'art': 0.0, 'stu': 0.0, 'lib': 0.0, 'doc': 0.0, 'sci': 0.0, 'wri': 0.0, 'law': 0.0, 'ent': 0.0, 'pro': 0.0}, 'tec')\n",
      "cluster number\n",
      "58\n",
      "caracteristics of cluster\n",
      "({'oth': 0.0, 'edu': 0.0, 'eng': 0.0, 'hea': 0.0, 'sal': 0.0, 'hom': 0.0, 'tec': 0.037037037037037035, 'exe': 0.0, 'non': 0.0, 'mar': 0.0, 'ret': 0.0, 'adm': 0.012658227848101266, 'art': 0.0, 'stu': 0.00510204081632653, 'lib': 0.0, 'doc': 0.0, 'sci': 0.0, 'wri': 0.0, 'law': 0.0, 'ent': 0.05555555555555555, 'pro': 0.015151515151515152}, 'ent')\n",
      "cluster number\n",
      "59\n",
      "caracteristics of cluster\n",
      "({'oth': 0.0, 'edu': 0.0, 'eng': 0.0, 'hea': 0.0, 'sal': 0.0, 'hom': 0.0, 'tec': 0.0, 'exe': 0.0, 'non': 0.0, 'mar': 0.0, 'ret': 0.0, 'adm': 0.0, 'art': 0.0, 'stu': 0.0, 'lib': 0.0196078431372549, 'doc': 0.0, 'sci': 0.0, 'wri': 0.0, 'law': 0.0, 'ent': 0.0, 'pro': 0.0}, 'lib')\n",
      "cluster number\n",
      "60\n",
      "caracteristics of cluster\n",
      "({'oth': 0.09523809523809523, 'edu': 0.08421052631578947, 'eng': 0.029850746268656716, 'hea': 0.0625, 'sal': 0.3333333333333333, 'hom': 0.2857142857142857, 'tec': 0.07407407407407407, 'exe': 0.0625, 'non': 0.1111111111111111, 'mar': 0.10714285714285714, 'ret': 0.07142857142857142, 'adm': 0.08860759493670886, 'art': 0.10714285714285714, 'stu': 0.04081632653061224, 'lib': 0.0196078431372549, 'doc': 0.2857142857142857, 'sci': 0.0967741935483871, 'wri': 0.08888888888888889, 'law': 0.08333333333333333, 'ent': 0.16666666666666666, 'pro': 0.045454545454545456}, 'sal')\n",
      "cluster number\n",
      "61\n",
      "caracteristics of cluster\n",
      "({'oth': 0.009523809523809525, 'edu': 0.010526315789473684, 'eng': 0.0, 'hea': 0.0, 'sal': 0.16666666666666666, 'hom': 0.0, 'tec': 0.0, 'exe': 0.03125, 'non': 0.0, 'mar': 0.0, 'ret': 0.0, 'adm': 0.012658227848101266, 'art': 0.0, 'stu': 0.01020408163265306, 'lib': 0.0, 'doc': 0.0, 'sci': 0.0, 'wri': 0.022222222222222223, 'law': 0.08333333333333333, 'ent': 0.0, 'pro': 0.0}, 'sal')\n",
      "cluster number\n",
      "62\n",
      "caracteristics of cluster\n",
      "({'oth': 0.009523809523809525, 'edu': 0.0, 'eng': 0.0, 'hea': 0.0, 'sal': 0.0, 'hom': 0.0, 'tec': 0.037037037037037035, 'exe': 0.03125, 'non': 0.0, 'mar': 0.0, 'ret': 0.0, 'adm': 0.012658227848101266, 'art': 0.0, 'stu': 0.01020408163265306, 'lib': 0.0196078431372549, 'doc': 0.0, 'sci': 0.0, 'wri': 0.0, 'law': 0.0, 'ent': 0.0, 'pro': 0.015151515151515152}, 'tec')\n",
      "cluster number\n",
      "63\n",
      "caracteristics of cluster\n",
      "({'oth': 0.0, 'edu': 0.0, 'eng': 0.029850746268656716, 'hea': 0.0, 'sal': 0.0, 'hom': 0.0, 'tec': 0.0, 'exe': 0.0, 'non': 0.0, 'mar': 0.0, 'ret': 0.0, 'adm': 0.012658227848101266, 'art': 0.0, 'stu': 0.0, 'lib': 0.0, 'doc': 0.0, 'sci': 0.0, 'wri': 0.0, 'law': 0.08333333333333333, 'ent': 0.0, 'pro': 0.0}, 'law')\n",
      "cluster number\n",
      "64\n",
      "caracteristics of cluster\n",
      "({'oth': 0.0, 'edu': 0.0, 'eng': 0.0, 'hea': 0.0, 'sal': 0.0, 'hom': 0.0, 'tec': 0.0, 'exe': 0.0, 'non': 0.0, 'mar': 0.0, 'ret': 0.0, 'adm': 0.0, 'art': 0.0, 'stu': 0.00510204081632653, 'lib': 0.0, 'doc': 0.0, 'sci': 0.0, 'wri': 0.0, 'law': 0.0, 'ent': 0.0, 'pro': 0.0}, 'stu')\n",
      "cluster number\n",
      "65\n",
      "caracteristics of cluster\n",
      "({'oth': 0.01904761904761905, 'edu': 0.042105263157894736, 'eng': 0.014925373134328358, 'hea': 0.0, 'sal': 0.0, 'hom': 0.0, 'tec': 0.0, 'exe': 0.03125, 'non': 0.1111111111111111, 'mar': 0.0, 'ret': 0.14285714285714285, 'adm': 0.0379746835443038, 'art': 0.07142857142857142, 'stu': 0.015306122448979591, 'lib': 0.0196078431372549, 'doc': 0.0, 'sci': 0.03225806451612903, 'wri': 0.0, 'law': 0.08333333333333333, 'ent': 0.0, 'pro': 0.015151515151515152}, 'ret')\n",
      "cluster number\n",
      "66\n",
      "caracteristics of cluster\n",
      "({'oth': 0.009523809523809525, 'edu': 0.0, 'eng': 0.0, 'hea': 0.0, 'sal': 0.0, 'hom': 0.0, 'tec': 0.0, 'exe': 0.0, 'non': 0.0, 'mar': 0.0, 'ret': 0.0, 'adm': 0.0, 'art': 0.0, 'stu': 0.0, 'lib': 0.0, 'doc': 0.0, 'sci': 0.0, 'wri': 0.0, 'law': 0.0, 'ent': 0.0, 'pro': 0.0}, 'oth')\n",
      "cluster number\n",
      "67\n",
      "caracteristics of cluster\n",
      "({'oth': 0.02857142857142857, 'edu': 0.010526315789473684, 'eng': 0.014925373134328358, 'hea': 0.0, 'sal': 0.0, 'hom': 0.0, 'tec': 0.0, 'exe': 0.0, 'non': 0.1111111111111111, 'mar': 0.0, 'ret': 0.07142857142857142, 'adm': 0.0379746835443038, 'art': 0.0, 'stu': 0.04081632653061224, 'lib': 0.0, 'doc': 0.0, 'sci': 0.06451612903225806, 'wri': 0.0, 'law': 0.0, 'ent': 0.0, 'pro': 0.015151515151515152}, 'non')\n",
      "cluster number\n",
      "68\n",
      "caracteristics of cluster\n",
      "({'oth': 0.0, 'edu': 0.0, 'eng': 0.0, 'hea': 0.0, 'sal': 0.0, 'hom': 0.0, 'tec': 0.0, 'exe': 0.0, 'non': 0.0, 'mar': 0.0, 'ret': 0.0, 'adm': 0.0, 'art': 0.0, 'stu': 0.00510204081632653, 'lib': 0.0, 'doc': 0.0, 'sci': 0.0, 'wri': 0.0, 'law': 0.0, 'ent': 0.0, 'pro': 0.0}, 'stu')\n",
      "cluster number\n",
      "69\n",
      "caracteristics of cluster\n",
      "({'oth': 0.01904761904761905, 'edu': 0.0, 'eng': 0.0, 'hea': 0.0, 'sal': 0.0, 'hom': 0.0, 'tec': 0.0, 'exe': 0.0, 'non': 0.0, 'mar': 0.0, 'ret': 0.0, 'adm': 0.0, 'art': 0.0, 'stu': 0.0, 'lib': 0.0, 'doc': 0.0, 'sci': 0.0, 'wri': 0.0, 'law': 0.0, 'ent': 0.0, 'pro': 0.0}, 'oth')\n",
      "cluster number\n",
      "70\n",
      "caracteristics of cluster\n",
      "({'oth': 0.0, 'edu': 0.010526315789473684, 'eng': 0.0, 'hea': 0.0, 'sal': 0.0, 'hom': 0.0, 'tec': 0.0, 'exe': 0.0, 'non': 0.0, 'mar': 0.0, 'ret': 0.0, 'adm': 0.0, 'art': 0.0, 'stu': 0.015306122448979591, 'lib': 0.0, 'doc': 0.0, 'sci': 0.0, 'wri': 0.0, 'law': 0.0, 'ent': 0.0, 'pro': 0.0}, 'stu')\n",
      "cluster number\n",
      "71\n",
      "caracteristics of cluster\n",
      "({'oth': 0.009523809523809525, 'edu': 0.0, 'eng': 0.0, 'hea': 0.0, 'sal': 0.0, 'hom': 0.0, 'tec': 0.0, 'exe': 0.0, 'non': 0.0, 'mar': 0.0, 'ret': 0.0, 'adm': 0.0, 'art': 0.0, 'stu': 0.0, 'lib': 0.0, 'doc': 0.0, 'sci': 0.0, 'wri': 0.0, 'law': 0.0, 'ent': 0.0, 'pro': 0.0}, 'oth')\n",
      "cluster number\n",
      "72\n",
      "caracteristics of cluster\n",
      "({'oth': 0.0, 'edu': 0.0, 'eng': 0.0, 'hea': 0.0, 'sal': 0.0, 'hom': 0.0, 'tec': 0.0, 'exe': 0.0, 'non': 0.0, 'mar': 0.0, 'ret': 0.0, 'adm': 0.0, 'art': 0.0, 'stu': 0.0, 'lib': 0.0, 'doc': 0.0, 'sci': 0.0, 'wri': 0.0, 'law': 0.0, 'ent': 0.0, 'pro': 0.015151515151515152}, 'pro')\n",
      "cluster number\n",
      "73\n",
      "caracteristics of cluster\n",
      "({'oth': 0.009523809523809525, 'edu': 0.010526315789473684, 'eng': 0.0, 'hea': 0.0, 'sal': 0.0, 'hom': 0.0, 'tec': 0.0, 'exe': 0.0, 'non': 0.0, 'mar': 0.0, 'ret': 0.0, 'adm': 0.0, 'art': 0.0, 'stu': 0.0, 'lib': 0.0, 'doc': 0.0, 'sci': 0.0, 'wri': 0.022222222222222223, 'law': 0.0, 'ent': 0.0, 'pro': 0.0}, 'wri')\n",
      "cluster number\n",
      "74\n",
      "caracteristics of cluster\n",
      "({'oth': 0.0, 'edu': 0.0, 'eng': 0.0, 'hea': 0.0, 'sal': 0.0, 'hom': 0.0, 'tec': 0.0, 'exe': 0.0, 'non': 0.0, 'mar': 0.0, 'ret': 0.0, 'adm': 0.0, 'art': 0.0, 'stu': 0.00510204081632653, 'lib': 0.0, 'doc': 0.0, 'sci': 0.0, 'wri': 0.0, 'law': 0.0, 'ent': 0.0, 'pro': 0.0}, 'stu')\n",
      "cluster number\n",
      "75\n",
      "caracteristics of cluster\n",
      "({'oth': 0.0, 'edu': 0.010526315789473684, 'eng': 0.014925373134328358, 'hea': 0.0625, 'sal': 0.0, 'hom': 0.0, 'tec': 0.0, 'exe': 0.0, 'non': 0.0, 'mar': 0.0, 'ret': 0.0, 'adm': 0.02531645569620253, 'art': 0.03571428571428571, 'stu': 0.00510204081632653, 'lib': 0.0, 'doc': 0.0, 'sci': 0.0, 'wri': 0.0, 'law': 0.0, 'ent': 0.0, 'pro': 0.015151515151515152}, 'hea')\n",
      "cluster number\n",
      "76\n",
      "caracteristics of cluster\n",
      "({'oth': 0.0, 'edu': 0.010526315789473684, 'eng': 0.0, 'hea': 0.0, 'sal': 0.0, 'hom': 0.0, 'tec': 0.0, 'exe': 0.0, 'non': 0.0, 'mar': 0.0, 'ret': 0.0, 'adm': 0.0, 'art': 0.0, 'stu': 0.0, 'lib': 0.0, 'doc': 0.0, 'sci': 0.0, 'wri': 0.0, 'law': 0.0, 'ent': 0.0, 'pro': 0.0}, 'edu')\n",
      "cluster number\n",
      "77\n",
      "caracteristics of cluster\n",
      "({'oth': 0.009523809523809525, 'edu': 0.010526315789473684, 'eng': 0.014925373134328358, 'hea': 0.0, 'sal': 0.0, 'hom': 0.0, 'tec': 0.0, 'exe': 0.03125, 'non': 0.0, 'mar': 0.0, 'ret': 0.0, 'adm': 0.02531645569620253, 'art': 0.0, 'stu': 0.0, 'lib': 0.0, 'doc': 0.0, 'sci': 0.0, 'wri': 0.022222222222222223, 'law': 0.0, 'ent': 0.0, 'pro': 0.0}, 'exe')\n",
      "cluster number\n",
      "78\n",
      "caracteristics of cluster\n",
      "({'oth': 0.0, 'edu': 0.0, 'eng': 0.0, 'hea': 0.0, 'sal': 0.0, 'hom': 0.0, 'tec': 0.0, 'exe': 0.0, 'non': 0.0, 'mar': 0.0, 'ret': 0.0, 'adm': 0.012658227848101266, 'art': 0.0, 'stu': 0.0, 'lib': 0.0, 'doc': 0.0, 'sci': 0.0, 'wri': 0.0, 'law': 0.0, 'ent': 0.0, 'pro': 0.0}, 'adm')\n",
      "cluster number\n",
      "79\n",
      "caracteristics of cluster\n",
      "({'oth': 0.02857142857142857, 'edu': 0.05263157894736842, 'eng': 0.13432835820895522, 'hea': 0.0, 'sal': 0.0, 'hom': 0.0, 'tec': 0.037037037037037035, 'exe': 0.03125, 'non': 0.0, 'mar': 0.07142857142857142, 'ret': 0.0, 'adm': 0.02531645569620253, 'art': 0.14285714285714285, 'stu': 0.030612244897959183, 'lib': 0.0392156862745098, 'doc': 0.14285714285714285, 'sci': 0.12903225806451613, 'wri': 0.022222222222222223, 'law': 0.0, 'ent': 0.05555555555555555, 'pro': 0.07575757575757576}, 'art')\n",
      "cluster number\n",
      "80\n",
      "caracteristics of cluster\n",
      "({'oth': 0.0, 'edu': 0.0, 'eng': 0.0, 'hea': 0.0, 'sal': 0.0, 'hom': 0.0, 'tec': 0.0, 'exe': 0.03125, 'non': 0.0, 'mar': 0.0, 'ret': 0.0, 'adm': 0.0, 'art': 0.0, 'stu': 0.0, 'lib': 0.0, 'doc': 0.0, 'sci': 0.0, 'wri': 0.0, 'law': 0.0, 'ent': 0.0, 'pro': 0.0}, 'exe')\n",
      "cluster number\n",
      "81\n",
      "caracteristics of cluster\n",
      "({'oth': 0.0, 'edu': 0.0, 'eng': 0.014925373134328358, 'hea': 0.0, 'sal': 0.0, 'hom': 0.0, 'tec': 0.037037037037037035, 'exe': 0.0, 'non': 0.0, 'mar': 0.0, 'ret': 0.0, 'adm': 0.0, 'art': 0.0, 'stu': 0.01020408163265306, 'lib': 0.0, 'doc': 0.0, 'sci': 0.0, 'wri': 0.0, 'law': 0.0, 'ent': 0.0, 'pro': 0.0}, 'tec')\n",
      "cluster number\n",
      "82\n",
      "caracteristics of cluster\n",
      "({'oth': 0.0, 'edu': 0.0, 'eng': 0.0, 'hea': 0.0, 'sal': 0.0, 'hom': 0.0, 'tec': 0.037037037037037035, 'exe': 0.0, 'non': 0.0, 'mar': 0.017857142857142856, 'ret': 0.0, 'adm': 0.012658227848101266, 'art': 0.03571428571428571, 'stu': 0.00510204081632653, 'lib': 0.0, 'doc': 0.0, 'sci': 0.0, 'wri': 0.0, 'law': 0.0, 'ent': 0.0, 'pro': 0.045454545454545456}, 'pro')\n",
      "cluster number\n",
      "83\n",
      "caracteristics of cluster\n",
      "({'oth': 0.0, 'edu': 0.0, 'eng': 0.0, 'hea': 0.0, 'sal': 0.0, 'hom': 0.0, 'tec': 0.037037037037037035, 'exe': 0.0, 'non': 0.0, 'mar': 0.0, 'ret': 0.0, 'adm': 0.0, 'art': 0.0, 'stu': 0.02040816326530612, 'lib': 0.0, 'doc': 0.0, 'sci': 0.0, 'wri': 0.0, 'law': 0.0, 'ent': 0.0, 'pro': 0.0}, 'tec')\n",
      "cluster number\n",
      "84\n",
      "caracteristics of cluster\n",
      "({'oth': 0.009523809523809525, 'edu': 0.010526315789473684, 'eng': 0.014925373134328358, 'hea': 0.0, 'sal': 0.0, 'hom': 0.0, 'tec': 0.0, 'exe': 0.0, 'non': 0.0, 'mar': 0.0, 'ret': 0.0, 'adm': 0.0, 'art': 0.0, 'stu': 0.00510204081632653, 'lib': 0.0, 'doc': 0.0, 'sci': 0.0, 'wri': 0.0, 'law': 0.0, 'ent': 0.0, 'pro': 0.0}, 'eng')\n",
      "cluster number\n",
      "85\n",
      "caracteristics of cluster\n",
      "({'oth': 0.01904761904761905, 'edu': 0.0, 'eng': 0.029850746268656716, 'hea': 0.0, 'sal': 0.0, 'hom': 0.0, 'tec': 0.0, 'exe': 0.0, 'non': 0.0, 'mar': 0.0, 'ret': 0.0, 'adm': 0.0, 'art': 0.0, 'stu': 0.0, 'lib': 0.0, 'doc': 0.0, 'sci': 0.0, 'wri': 0.0, 'law': 0.0, 'ent': 0.0, 'pro': 0.0}, 'eng')\n",
      "cluster number\n",
      "86\n",
      "caracteristics of cluster\n",
      "({'oth': 0.01904761904761905, 'edu': 0.021052631578947368, 'eng': 0.0, 'hea': 0.0, 'sal': 0.0, 'hom': 0.0, 'tec': 0.0, 'exe': 0.03125, 'non': 0.0, 'mar': 0.0, 'ret': 0.07142857142857142, 'adm': 0.012658227848101266, 'art': 0.07142857142857142, 'stu': 0.02040816326530612, 'lib': 0.0196078431372549, 'doc': 0.0, 'sci': 0.03225806451612903, 'wri': 0.0, 'law': 0.0, 'ent': 0.0, 'pro': 0.015151515151515152}, 'ret')\n",
      "cluster number\n",
      "87\n",
      "caracteristics of cluster\n",
      "({'oth': 0.0, 'edu': 0.0, 'eng': 0.0, 'hea': 0.0, 'sal': 0.0, 'hom': 0.0, 'tec': 0.0, 'exe': 0.03125, 'non': 0.1111111111111111, 'mar': 0.0, 'ret': 0.0, 'adm': 0.0, 'art': 0.0, 'stu': 0.00510204081632653, 'lib': 0.0, 'doc': 0.0, 'sci': 0.0, 'wri': 0.0, 'law': 0.0, 'ent': 0.0, 'pro': 0.0}, 'non')\n",
      "cluster number\n",
      "88\n",
      "caracteristics of cluster\n",
      "({'oth': 0.0, 'edu': 0.042105263157894736, 'eng': 0.0, 'hea': 0.0, 'sal': 0.0, 'hom': 0.0, 'tec': 0.0, 'exe': 0.0, 'non': 0.0, 'mar': 0.0, 'ret': 0.07142857142857142, 'adm': 0.0, 'art': 0.03571428571428571, 'stu': 0.0, 'lib': 0.0196078431372549, 'doc': 0.0, 'sci': 0.0, 'wri': 0.0, 'law': 0.08333333333333333, 'ent': 0.0, 'pro': 0.0}, 'law')\n",
      "cluster number\n",
      "89\n",
      "caracteristics of cluster\n",
      "({'oth': 0.0, 'edu': 0.0, 'eng': 0.0, 'hea': 0.0, 'sal': 0.0, 'hom': 0.0, 'tec': 0.0, 'exe': 0.0, 'non': 0.0, 'mar': 0.0, 'ret': 0.0, 'adm': 0.0, 'art': 0.0, 'stu': 0.0, 'lib': 0.0, 'doc': 0.0, 'sci': 0.0, 'wri': 0.0, 'law': 0.0, 'ent': 0.0, 'pro': 0.015151515151515152}, 'pro')\n",
      "cluster number\n",
      "90\n",
      "caracteristics of cluster\n",
      "({'oth': 0.01904761904761905, 'edu': 0.031578947368421054, 'eng': 0.014925373134328358, 'hea': 0.0, 'sal': 0.0, 'hom': 0.0, 'tec': 0.0, 'exe': 0.03125, 'non': 0.0, 'mar': 0.03571428571428571, 'ret': 0.07142857142857142, 'adm': 0.05063291139240506, 'art': 0.0, 'stu': 0.01020408163265306, 'lib': 0.058823529411764705, 'doc': 0.0, 'sci': 0.03225806451612903, 'wri': 0.08888888888888889, 'law': 0.0, 'ent': 0.0, 'pro': 0.0}, 'wri')\n",
      "cluster number\n",
      "91\n",
      "caracteristics of cluster\n",
      "({'oth': 0.009523809523809525, 'edu': 0.0, 'eng': 0.014925373134328358, 'hea': 0.0, 'sal': 0.0, 'hom': 0.0, 'tec': 0.0, 'exe': 0.0, 'non': 0.0, 'mar': 0.0, 'ret': 0.0, 'adm': 0.012658227848101266, 'art': 0.0, 'stu': 0.00510204081632653, 'lib': 0.0196078431372549, 'doc': 0.0, 'sci': 0.0, 'wri': 0.022222222222222223, 'law': 0.0, 'ent': 0.0, 'pro': 0.0}, 'wri')\n",
      "cluster number\n",
      "92\n",
      "caracteristics of cluster\n",
      "({'oth': 0.01904761904761905, 'edu': 0.010526315789473684, 'eng': 0.014925373134328358, 'hea': 0.0, 'sal': 0.0, 'hom': 0.0, 'tec': 0.0, 'exe': 0.0, 'non': 0.0, 'mar': 0.0, 'ret': 0.0, 'adm': 0.012658227848101266, 'art': 0.0, 'stu': 0.00510204081632653, 'lib': 0.0, 'doc': 0.0, 'sci': 0.0, 'wri': 0.0, 'law': 0.0, 'ent': 0.0, 'pro': 0.015151515151515152}, 'oth')\n",
      "cluster number\n",
      "93\n",
      "caracteristics of cluster\n",
      "({'oth': 0.0, 'edu': 0.0, 'eng': 0.029850746268656716, 'hea': 0.0, 'sal': 0.0, 'hom': 0.0, 'tec': 0.0, 'exe': 0.0, 'non': 0.0, 'mar': 0.0, 'ret': 0.0, 'adm': 0.0, 'art': 0.0, 'stu': 0.015306122448979591, 'lib': 0.0, 'doc': 0.0, 'sci': 0.0, 'wri': 0.0, 'law': 0.0, 'ent': 0.0, 'pro': 0.0}, 'eng')\n",
      "cluster number\n",
      "94\n",
      "caracteristics of cluster\n",
      "({'oth': 0.0, 'edu': 0.0, 'eng': 0.029850746268656716, 'hea': 0.0, 'sal': 0.0, 'hom': 0.0, 'tec': 0.037037037037037035, 'exe': 0.0, 'non': 0.0, 'mar': 0.0, 'ret': 0.0, 'adm': 0.012658227848101266, 'art': 0.0, 'stu': 0.00510204081632653, 'lib': 0.0196078431372549, 'doc': 0.0, 'sci': 0.0, 'wri': 0.0, 'law': 0.0, 'ent': 0.0, 'pro': 0.045454545454545456}, 'pro')\n",
      "cluster number\n",
      "95\n",
      "caracteristics of cluster\n",
      "({'oth': 0.0, 'edu': 0.021052631578947368, 'eng': 0.0, 'hea': 0.0, 'sal': 0.0, 'hom': 0.0, 'tec': 0.0, 'exe': 0.0, 'non': 0.0, 'mar': 0.0, 'ret': 0.07142857142857142, 'adm': 0.012658227848101266, 'art': 0.0, 'stu': 0.01020408163265306, 'lib': 0.0196078431372549, 'doc': 0.0, 'sci': 0.0, 'wri': 0.0, 'law': 0.0, 'ent': 0.0, 'pro': 0.0}, 'ret')\n",
      "cluster number\n",
      "96\n",
      "caracteristics of cluster\n",
      "({'oth': 0.0, 'edu': 0.0, 'eng': 0.0, 'hea': 0.0, 'sal': 0.0, 'hom': 0.0, 'tec': 0.0, 'exe': 0.0, 'non': 0.0, 'mar': 0.0, 'ret': 0.0, 'adm': 0.0, 'art': 0.03571428571428571, 'stu': 0.0, 'lib': 0.0, 'doc': 0.0, 'sci': 0.0, 'wri': 0.0, 'law': 0.0, 'ent': 0.0, 'pro': 0.015151515151515152}, 'art')\n",
      "cluster number\n",
      "97\n",
      "caracteristics of cluster\n",
      "({'oth': 0.0, 'edu': 0.010526315789473684, 'eng': 0.014925373134328358, 'hea': 0.0, 'sal': 0.0, 'hom': 0.0, 'tec': 0.0, 'exe': 0.0, 'non': 0.0, 'mar': 0.0, 'ret': 0.0, 'adm': 0.012658227848101266, 'art': 0.0, 'stu': 0.0, 'lib': 0.0, 'doc': 0.0, 'sci': 0.0, 'wri': 0.0, 'law': 0.0, 'ent': 0.0, 'pro': 0.0}, 'eng')\n",
      "cluster number\n",
      "98\n",
      "caracteristics of cluster\n",
      "({'oth': 0.0, 'edu': 0.010526315789473684, 'eng': 0.0, 'hea': 0.0, 'sal': 0.0, 'hom': 0.0, 'tec': 0.0, 'exe': 0.0, 'non': 0.0, 'mar': 0.0, 'ret': 0.0, 'adm': 0.0, 'art': 0.0, 'stu': 0.0, 'lib': 0.0, 'doc': 0.0, 'sci': 0.0, 'wri': 0.0, 'law': 0.0, 'ent': 0.0, 'pro': 0.0}, 'edu')\n",
      "cluster number\n",
      "99\n",
      "caracteristics of cluster\n",
      "({'oth': 0.009523809523809525, 'edu': 0.0, 'eng': 0.014925373134328358, 'hea': 0.0625, 'sal': 0.0, 'hom': 0.0, 'tec': 0.0, 'exe': 0.0, 'non': 0.0, 'mar': 0.017857142857142856, 'ret': 0.0, 'adm': 0.012658227848101266, 'art': 0.0, 'stu': 0.0, 'lib': 0.0, 'doc': 0.0, 'sci': 0.0, 'wri': 0.0, 'law': 0.0, 'ent': 0.0, 'pro': 0.015151515151515152}, 'hea')\n"
     ]
    }
   ],
   "source": [
    "for i in range(nbClusters):\n",
    "    print(\"cluster number\")\n",
    "    print(i)\n",
    "    print(\"caracteristics of cluster\")\n",
    "    print(caractCluster(i,associatedUsers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Scalar product between normalized vectors of users and films\n",
    "def closest(centersFilms, centersUsers):\n",
    "    #result = {}\n",
    "    k_films = len(centersFilms)\n",
    "    print(\"k_films\")\n",
    "    print(k_films)\n",
    "    k_users = len(centersUsers)\n",
    "    print(\"k_users\")\n",
    "    print(k_users)\n",
    "    for i in range(k_users):\n",
    "        a = np.array(centersUsers[i])/np.linalg.norm(np.array(centersUsers[i]))\n",
    "        for j in range(0,k_films):\n",
    "            b = np.array(centersFilms[j])/np.linalg.norm(np.array(centersFilms[j]))\n",
    "    #Example :\n",
    "    print(a @ b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k_films\n",
      "100\n",
      "k_users\n",
      "100\n",
      "0.293315662987\n"
     ]
    }
   ],
   "source": [
    "#Figure 9\n",
    "\n",
    "#Segmentation and interpretation of clusters with sklearn\n",
    "\n",
    "\n",
    "###########################################\n",
    "# Attribute users to films\n",
    "###########################################\n",
    "\n",
    "closest(centersFilms, centersUsers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction with K-Means++\n",
    "\n",
    "In our project, we use K-Means++ as a clustering method. But it is also possible to apply K-Means++ to prediction problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Find the coordinate j of the center corresponding to a point\n",
    "def findCenter(usersClusters, centersClusters, user,j):\n",
    "    val = usersClusters.values()\n",
    "    nbClusters = len(centersClusters)\n",
    "    indexCenter = 0\n",
    "    for i in range(nbClusters):\n",
    "        if any((x == user).all() for x in usersClusters[i]): #if user (which is an array) in users_clusters[i]:\n",
    "            indexCenter = i\n",
    "            break\n",
    "    return centersClusters[indexCenter][j]\n",
    "\n",
    "#Create dictionary with predicted ratings\n",
    "def predictKMeans (rowMean,ratedTest,Matrix):\n",
    "    dictionary = {}\n",
    "    for i in ratedTest:\n",
    "        for j in ratedTest[i]:\n",
    "            bary = findCenter(usersClusters,centersClusters,Matrix[i],j)\n",
    "            dictionary[(i,j)] =  roundDown(rowMean[i] + bary)\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.639034955929\n"
     ]
    }
   ],
   "source": [
    "steps=30\n",
    "nbClusters=15\n",
    "\n",
    "# Normalize matrix\n",
    "ratings = replace0s(ratingsTrain, rowMean)\n",
    "\n",
    "(usersClusters,centersClusters)=kmeansPP(ratings, nbClusters, steps)\n",
    "\n",
    "\n",
    "# Create dictionary with predicted ratings\n",
    "ratings = predictKMeans(rowMean,ratedTest,ratings)\n",
    "\n",
    "\n",
    "#Calculate accuracy\n",
    "print(calculateAccuracy(ratings,ratingsTestDic))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparse Non Negative Matrix Factorization (SNMF)\n",
    "\n",
    "In problems where dimension reduction is crucial, like image compressing, it is possible to restrict a matrix factor to its most important features only, using L1 norm penalization. (You want to use L0 norm, but can't for differentiability reasons. L1 is the closest and it works because it is not differentiable in 0).\n",
    "\n",
    "Here we force sparseness onto the factor Q of films.\n",
    "\n",
    "Refers to Algorithm 2 in article: http://www.jonathanleroux.org/pdf/LeRoux2015SparseNMF03.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update(A, P, Q, mu, r):\n",
    "    PQ = P @ Q\n",
    "    Q *= (P.T @ A) / (P.T @ PQ + mu)\n",
    "    PQ = P @ Q\n",
    "    oneNum = (P * (PQ @ Q.T)).sum(axis=0)\n",
    "    oneDen = (P * (A @ Q.T)).sum(axis=0)\n",
    "    P *= (A @ Q.T + P * np.matrix([oneDen for i in range(r)])) / (PQ @ Q.T + P * np.matrix([oneDen for i in range(r)]))\n",
    "    row_sums = (P**2).sum(axis=0)**0.5\n",
    "    P /= row_sums[np.newaxis,:]\n",
    "    return P, Q\n",
    "\n",
    "\n",
    "def SNMF(V, r, iterations=100, mu=0.1):\n",
    "    n, m = V.shape\n",
    "    P = np.random.random(n * r).reshape(n, r) * 4 + 1\n",
    "    Q = np.random.random(r * m).reshape(r, m) * 4 + 1\n",
    "    row_sums = (P**2).sum(axis=0)**0.5\n",
    "    P /= row_sums[np.newaxis,:]\n",
    "    for i in range(iterations):\n",
    "        P, Q = update(A, P, Q, mu, r)\n",
    "        PQ = P @ Q\n",
    "        euclidean = np.nansum((A-PQ)**2)\n",
    "    print(\"The euclidean distance is {d}\".format(d=euclidean))\n",
    "    return(P @ Q, P, Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The euclidean distance is 89005.38519427694\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[ 0.97361565,  0.9482587 ,  0.9760872 , ...,  0.92232144,\n",
       "          0.91054249,  0.92801189],\n",
       "        [ 1.07169906,  1.06991586,  1.07811814, ...,  0.9506623 ,\n",
       "          0.95678686,  0.9630954 ],\n",
       "        [ 0.97260784,  0.96954362,  0.96270912, ...,  1.00089893,\n",
       "          0.99124403,  0.99680802],\n",
       "        ..., \n",
       "        [ 1.28736925,  1.25381503,  1.27673459, ...,  4.93610052,\n",
       "          4.88801815,  4.92428058],\n",
       "        [ 1.19575742,  1.1603789 ,  1.18441069, ...,  4.98373545,\n",
       "          4.94419653,  4.96918314],\n",
       "        [ 1.20055212,  1.2200765 ,  1.19380339, ...,  4.97296964,\n",
       "          4.94380512,  4.96757113]]),\n",
       " array([[ 0.01651331,  0.01821933,  0.0315125 , ...,  0.02048187,\n",
       "          0.01419061,  0.01313434],\n",
       "        [ 0.03126246,  0.01925697,  0.0398307 , ...,  0.04284268,\n",
       "          0.02138491,  0.00861248],\n",
       "        [ 0.03917808,  0.02307068,  0.03800563, ...,  0.00885042,\n",
       "          0.02252872,  0.01472307],\n",
       "        ..., \n",
       "        [ 0.01571074,  0.18032179,  0.05713984, ...,  0.01797037,\n",
       "          0.03075551,  0.01043025],\n",
       "        [ 0.02172702,  0.18490355,  0.06672269, ...,  0.01237172,\n",
       "          0.03533911,  0.01200048],\n",
       "        [ 0.02283395,  0.19094674,  0.01998395, ...,  0.0305576 ,\n",
       "          0.01343762,  0.00581925]]),\n",
       " array([[  3.39756932,   3.73793814,   2.59635073, ...,   1.11782715,\n",
       "           0.93310483,   1.04433406],\n",
       "        [  2.34515862,   2.5623582 ,   2.41421453, ...,  23.74677091,\n",
       "          23.67665112,  23.69702348],\n",
       "        [  3.67473675,   2.4959065 ,   3.55906352, ...,   5.02107421,\n",
       "           4.64953075,   5.03809615],\n",
       "        ..., \n",
       "        [  4.4373203 ,   4.4088554 ,   4.96108938, ...,   0.3864675 ,\n",
       "           0.6947728 ,   0.73213728],\n",
       "        [  0.74342411,   0.78432318,   0.75194523, ...,   1.2484625 ,\n",
       "           1.16456916,   0.83181394],\n",
       "        [  1.65845403,   1.52911925,   1.26904952, ...,   0.27982387,\n",
       "           0.17424963,   0.19920763]]))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SNMF(A,15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted Sparse Non Negative Matrix Factorization (WSNMF) (Tentative name)\n",
    "\n",
    "We apply SNMF on a matrix with missing data. In order to accomplish it, we combine the WNMF method with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update(weightedA, P, Q, Weights, mu, r):\n",
    "    weightedPQ = Weights * (P @ Q)\n",
    "    Q *= (P.T @ weightedA) / (P.T @ weightedPQ + mu)\n",
    "    weightedPQ = Weights * (P @ Q)\n",
    "    oneNum = (P * (weightedPQ @ Q.T)).sum(axis=0)\n",
    "    oneDen = (P * (weightedA @ Q.T)).sum(axis=0)\n",
    "    P *= (weightedA @ Q.T + P * np.matrix([oneDen for i in range(r)])) / (weightedPQ @ Q.T + P * np.matrix([oneDen for i in range(r)]))\n",
    "    row_sums = (P**2).sum(axis=0)**0.5\n",
    "    P /= row_sums[np.newaxis,:]\n",
    "    return P, Q\n",
    "\n",
    "\n",
    "def WSNMF(A, r, iterations=100, mu=0.1):\n",
    "    n, m = A.shape\n",
    "    P = np.random.random(n * r).reshape(n, r) * 4 + 1\n",
    "    Q = np.random.random(r * m).reshape(r, m) * 4 + 1\n",
    "    Weights = A.copy()\n",
    "    Weights[Weights != 0] = 1\n",
    "    weightedA = Weights * A\n",
    "    row_sums = (P**2).sum(axis=0)**0.5\n",
    "    P /= row_sums[np.newaxis,:]\n",
    "    for i in range(iterations):\n",
    "        P, Q = update(weightedA, P, Q, Weights, mu, r)\n",
    "        PQ = P @ Q\n",
    "        weightedPQ = Weights * PQ\n",
    "        euclidean = np.nansum((weightedA-weightedPQ)**2)\n",
    "    print(\"The euclidean distance is {d}\".format(d=euclidean))\n",
    "    return(P @ Q, P, Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The euclidean distance is 44579.50412410784\n",
      "0.809294871795\n"
     ]
    }
   ],
   "source": [
    "# Create new matrix\n",
    "ratings,P,Q = WSNMF(ratingsTrain,9,1000)\n",
    "\n",
    "# Create dictionary with predicted ratings\n",
    "ratings = roundRatings(ratedTest,ratings,True)\n",
    "\n",
    "# Calculate accuracy\n",
    "print(calculateAccuracy(ratings,ratingsTestDic))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
